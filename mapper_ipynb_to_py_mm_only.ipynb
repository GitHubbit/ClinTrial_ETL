{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3072b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display cells to maximum width \n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd67bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import time\n",
    "from time import sleep\n",
    "import concurrent\n",
    "import multiprocessing\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import pathlib\n",
    "import configparser\n",
    "import sys\n",
    "import urllib\n",
    "import zipfile\n",
    "import csv\n",
    "sys.path.insert(0, '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/pymetamap-master')\n",
    "from pymetamap import MetaMap  # https://github.com/AnthonyMRios/pymetamap/blob/master/pymetamap/SubprocessBackend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f667354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install thefuzz\n",
    "# %pip install levenshtein\n",
    "\n",
    "from thefuzz import fuzz # fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1536a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "global metamap_dirs\n",
    "global metamap_pos_server_dir\n",
    "global metamap_wsd_server_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98643c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python\n",
    "\n",
    "def get_token_sort_ratio(str1, str2):\n",
    "    try:\n",
    "        return fuzz.token_sort_ratio(str1, str2)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "sort_ratio = np.vectorize(get_token_sort_ratio)\n",
    "\n",
    "def get_token_set_ratio(str1, str2):\n",
    "    try:\n",
    "        return fuzz.token_set_ratio(str1, str2)\n",
    "    except:\n",
    "        return None  \n",
    "set_ratio = np.vectorize(get_token_set_ratio)\n",
    "\n",
    "def get_similarity_score(str1, str2):\n",
    "    try:\n",
    "        return fuzz.ratio(str1, str2)\n",
    "    except:\n",
    "        return None\n",
    "sim_score = np.vectorize(get_similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b48cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_ct_data():\n",
    "    term_program_flag = True\n",
    "    global data_dir\n",
    "    global data_extracted\n",
    "    \n",
    "    # get all the links and associated dates of upload into a dict called date_link\n",
    "    url_all = \"https://aact.ctti-clinicaltrials.org/pipe_files\"\n",
    "    response = requests.get(url_all)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    body = soup.find_all('option') #Find all\n",
    "    date_link = {}\n",
    "    for el in body:\n",
    "        tags = el.find('a')\n",
    "        try:\n",
    "            zip_name = tags.contents[0].split()[0]\n",
    "            date = zip_name.split(\"_\")[0]\n",
    "            date = dt.datetime.strptime(date, '%Y%m%d').date()\n",
    "            date_link[date] = tags.get('href')\n",
    "        except:\n",
    "            pass\n",
    "    latest_file_date = max(date_link.keys())   # get the date of the latest upload\n",
    "    url = date_link[latest_file_date]   # get the corresponding download link of the latest upload so we can download the raw data\n",
    "    date_string = latest_file_date.strftime(\"%m_%d_%Y\")\n",
    "    data_dir = \"{}/data\".format(pathlib.Path.cwd())\n",
    "    data_extracted = data_dir + \"/{}_extracted\".format(date_string)\n",
    "    data_path = \"{}/{}_pipe-delimited-export.zip\".format(data_dir, date_string)\n",
    "    \n",
    "    if not os.path.exists(data_path):   # if folder containing most recent data doesn't exist, download and extract it into data folder\n",
    "        \n",
    "        term_program_flag = False   # flag below for terminating program if latest download exists (KG is assumed up to date)\n",
    "        print(\"Downloading Clinical Trial data as of {}\".format(date_string))\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(data_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(\"Finished download of zip\")\n",
    "            with zipfile.ZipFile(data_path, 'r') as download:\n",
    "                print(\"Unzipping data\")\n",
    "                download.extractall(data_extracted)\n",
    "        else:\n",
    "            print(\"KG is already up to date.\")\n",
    "    return {\"term_program_flag\": term_program_flag, \"data_extracted_path\": data_extracted, \"date_string\": date_string}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b1c9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_ct_data(flag_and_path):\n",
    "    if flag_and_path[\"term_program_flag\"]:\n",
    "        print(\"Exiting program. Assuming KG has already been constructed from most recent data dump from AACT.\")\n",
    "#         exit()\n",
    "#         pass\n",
    "    else:\n",
    "        data_extracted = flag_and_path[\"data_extracted_path\"]\n",
    "        # read in pipe-delimited files \n",
    "        conditions_df = pd.read_csv(data_extracted + '/conditions.txt', sep='|', index_col=False, header=0)\n",
    "        interventions_df = pd.read_csv(data_extracted + '/interventions.txt', sep='|', index_col=False, header=0)\n",
    "#         browse_conditions_df = pd.read_csv(data_extracted + '/browse_conditions.txt', sep='|', index_col=False, header=0)\n",
    "#         browse_interventions_df = pd.read_csv(data_extracted + '/browse_interventions.txt', sep='|', index_col=False, header=0)\n",
    "        \n",
    "    ### GET RID OF....CHEAT LINE FOR TESTING\n",
    "        conditions_df = conditions_df.iloc[:1000]\n",
    "        interventions_df = interventions_df.iloc[:1000]\n",
    "\n",
    "    return {\"conditions\": conditions_df, \"interventions\": interventions_df\n",
    "#             \"browse_conditions\": browse_conditions_df, \"browse_interventions\": browse_interventions_df\n",
    "           }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9461c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_ascii_er(text):\n",
    "    non_ascii = \"[^\\x00-\\x7F]\"\n",
    "    pattern = re.compile(r\"[^\\x00-\\x7F]\")\n",
    "    non_ascii_text = re.sub(pattern, ' ', text)\n",
    "    return non_ascii_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd31274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_metamap_servers(metamap_dirs):\n",
    "    metamap_pos_server_dir = 'bin/skrmedpostctl' # Part of speech tagger\n",
    "    metamap_wsd_server_dir = 'bin/wsdserverctl' # Word sense disambiguation \n",
    "    \n",
    "    # Start servers\n",
    "    os.system(metamap_dirs['metamap_base_dir'] + metamap_pos_server_dir + ' start') # Part of speech tagger\n",
    "    os.system(metamap_dirs['metamap_base_dir'] + metamap_wsd_server_dir + ' start') # Word sense disambiguation \n",
    "    # # Sleep a bit to give time for these servers to start up\n",
    "    sleep(5)\n",
    "\n",
    "def stop_metamap_servers(metamap_dirs):\n",
    "    metamap_pos_server_dir = 'bin/skrmedpostctl' # Part of speech tagger\n",
    "    metamap_wsd_server_dir = 'bin/wsdserverctl' # Word sense disambiguation \n",
    "    # Stop servers\n",
    "    os.system(metamap_dirs['metamap_base_dir'] + metamap_pos_server_dir + ' stop') # Part of speech tagger\n",
    "    os.system(metamap_dirs['metamap_base_dir'] + metamap_wsd_server_dir + ' stop') # Word sense disambiguation \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64b4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_os():\n",
    "    if \"linux\" in sys.platform:\n",
    "        print(\"Linux platform detected\")\n",
    "        metamap_base_dir = \"{}/metamap/\".format(pathlib.Path.cwd().parents[0])\n",
    "        metamap_bin_dir = 'bin/metamap20'\n",
    "    else:\n",
    "        metamap_base_dir = '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/public_mm/' # for running on local\n",
    "        metamap_bin_dir = 'bin/metamap18'\n",
    "        \n",
    "    return {\"metamap_base_dir\":metamap_base_dir, \"metamap_bin_dir\":metamap_bin_dir}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f51f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_metamap(input_term, source_restriction):\n",
    "#     concepts_dict = dict()\n",
    "#     if all(x is None for x in source_restriction):\n",
    "#         try:\n",
    "#             concepts,error = mm.extract_concepts([input_term],\n",
    "#                                                  word_sense_disambiguation = True,\n",
    "#                                                  prune = 10,\n",
    "#                                                  composite_phrase = 1)\n",
    "#             concepts_dict[input_term] = concepts\n",
    "#         except:\n",
    "#             concepts_dict[input_term] = None \n",
    "#     else:\n",
    "#         try:\n",
    "#             concepts,error = mm.extract_concepts([input_term],\n",
    "#                                                  word_sense_disambiguation = True,\n",
    "#                                                  restrict_to_sources=source_restriction,\n",
    "#                                                  prune = 10,\n",
    "#                                                  composite_phrase = 1)\n",
    "#             concepts_dict[input_term] = concepts\n",
    "#         except:\n",
    "#             concepts_dict[input_term] = None \n",
    "#     return(concepts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "691b0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metamap(input_term, params, mm, cond_or_inter, csv_writer):\n",
    "    from_metamap = []\n",
    "    try:\n",
    "        concepts,error = mm.extract_concepts([input_term],\n",
    "                                             restrict_to_sts = params[\"restrict_to_sts\"],\n",
    "                                             term_processing = params[\"term_processing\"],\n",
    "                                             ignore_word_order = params[\"ignore_word_order\"],\n",
    "                                             strict_model = params[\"strict_model\"]\n",
    "                                            )\n",
    "\n",
    "        for concept in concepts:\n",
    "            concept_info = []\n",
    "            concept = concept._asdict()\n",
    "            concept_info.extend([cond_or_inter,input_term])\n",
    "            concept_info.extend([concept.get(k) for k in ['preferred_name', 'cui', 'score', 'semtypes']])\n",
    "            from_metamap.append(concept_info)\n",
    "    except:\n",
    "        from_metamap.extend([input_term, None, None, None, None, None, None])\n",
    "    for result in from_metamap:\n",
    "#         print(result)\n",
    "        csv_writer.writerow(result)\n",
    "    return from_metamap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "093faf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['infarction, myocardial', 'aneurysm', 'diabetes', 'common cold', 'fracture', 'juice blend', \"hormones\"]\n",
    "\n",
    "condition_semantic_type_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "params = {\"restrict_to_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False}\n",
    "start_metamap_servers(metamap_dirs) # start the MetaMap servers\n",
    "mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "cond_or_inter = \"condition\"\n",
    "\n",
    "# prep file that stores MetaMap output\n",
    "col_names = ['term_type', 'clin_trial_term','metamap_preferred_name', 'metamap_cui', 'metamap_score', 'metamap_semantic_type']\n",
    "# metamap_output = open(\"metamap_output().tsv\".format(flag_and_path[\"date_string\"]), 'w+', newline='') \n",
    "metamap_output = open(\"metamap_output.tsv\", 'w+', newline='') \n",
    "csv_writer = csv.writer(metamap_output, delimiter='\\t')\n",
    "csv_writer.writerow(col_names)\n",
    "\n",
    "for term in terms:\n",
    "#     test = run_metamap(term, params, mm, cond_or_inter)\n",
    "    run_metamap(term, params, mm, cond_or_inter, csv_writer)\n",
    "metamap_output.close()    \n",
    "stop_metamap_servers(metamap_dirs) # stop the MetaMap servers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "816c6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_metamap(term_list, params, cond_or_inter, flag_and_path, csv_writer):\n",
    "    start_metamap_servers(metamap_dirs) # start the MetaMap servers\n",
    "    mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "    with concurrent.futures.ThreadPoolExecutor((multiprocessing.cpu_count()*2) - 1) as executor:\n",
    "#         run_metamap(term_list, params, mm, cond_or_inter, csv_writer)\n",
    "        _ = [executor.submit(run_metamap, term, params, mm, cond_or_inter, csv_writer) for term in term_list]\n",
    "    stop_metamap_servers(metamap_dirs) # stop the MetaMap servers\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "# def run_io_tasks_in_parallel(tasks):\n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         running_tasks = [executor.submit(task) for task in tasks]\n",
    "#         for running_task in running_tasks:\n",
    "#             running_task.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def run_parallel_threads_mm(terms_chunked, args):\n",
    "# def run_parallel_threads_mm(terms_list, params):\n",
    "\n",
    "#     start_metamap_servers(metamap_dirs)\n",
    "#     mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "#     # multithread implementation for retrieving MetaMap terms\n",
    "#     # Create a ThreadPoolExecutor with the desired number of threads\n",
    "#     with concurrent.futures.ThreadPoolExecutor(multiprocessing.cpu_count() - 1) as executor:\n",
    "#         # Submit the get_response() function for each item in the list\n",
    "# #         futures = [executor.submit(get_metamap_mappings, term, args) for term in terms_chunked]\n",
    "#         futures = [executor.submit(run_metamap, term, params, mm) for term in terms_list]\n",
    "\n",
    "#         # Retrieve the results as they become available\n",
    "#         output = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "#     mm_dict = reduce(lambda d1, d2: {**d1, **d2}, output) # merge the list of dicts of MetaMap responses in output into 1 dict\n",
    "#     stop_metamap_servers(metamap_dirs)\n",
    "#     return mm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340570d",
   "metadata": {},
   "source": [
    "# USE METAMAP LOCAL TO MAP REMAINING TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e85ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def run_parallel_threads_mm(terms_chunked, args):\n",
    "# def run_parallel_threads_mm(terms_list, args):\n",
    "#     mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "#     # multithread implementation for retrieving MetaMap terms\n",
    "#     # Create a ThreadPoolExecutor with the desired number of threads\n",
    "#     with concurrent.futures.ThreadPoolExecutor(multiprocessing.cpu_count() - 1) as executor:\n",
    "#         # Submit the get_response() function for each item in the list\n",
    "# #         futures = [executor.submit(get_metamap_mappings, term, args) for term in terms_chunked]\n",
    "#         futures = [executor.submit(run_metamap, term, args, mm) for term in terms_list]\n",
    "\n",
    "\n",
    "#         # Retrieve the results as they become available\n",
    "#         output = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "#     mm_dict = reduce(lambda d1, d2: {**d1, **d2}, output) # merge the list of dicts of MetaMap responses in output into 1 dict\n",
    "#     return mm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d2de05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_list_to_mm(df_dict, flag_and_path):\n",
    "    \n",
    "    # -------    CONDITIONS    ------- #\n",
    "    print(\"Using UMLS MetaMap to get mappings for conditions. MetaMap returns mappings, CUIs, and semantic type of mapping.\")\n",
    "    unmapped_conditions = df_dict[\"conditions\"].downcase_name\n",
    "    unmapped_conditions = list(unmapped_conditions.unique())\n",
    "    unmapped_conditions = list(filter(None, unmapped_conditions))\n",
    "\n",
    "    deasciied_unmapped_conditions = list(map(de_ascii_er, unmapped_conditions)) # Metamap 2020 does not need de_asciier. Metamap 2018 and prior does. \n",
    "\n",
    "    conditions = pd.DataFrame({'original_unmapped_conditions': unmapped_conditions, 'de_asciied_unmapped_conditions': deasciied_unmapped_conditions})\n",
    "    \n",
    "    # some input terms have () with additional text, like an abbreviation, in them. split them out to facilitate better mapping \n",
    "    \n",
    "    pattern_outisde = r'(?<=\\().+?(?=\\))|([^(]+)'\n",
    "    pattern_inside = r'\\(([^()]+)\\)|([^(]+)'\n",
    "\n",
    "    matches_outside = conditions['original_unmapped_conditions'].str.extract(pattern_outisde)\n",
    "    conditions['original_condition_split_1'] = matches_outside[0].fillna('')\n",
    "    matches_inside = conditions['original_unmapped_conditions'].str.extract(pattern_inside)\n",
    "    conditions['original_condition_split_2'] = matches_inside[0].fillna('')\n",
    "\n",
    "    matches_outside = conditions['de_asciied_unmapped_conditions'].str.extract(pattern_outisde)\n",
    "    conditions['de_asciied_conditions_split_1'] = matches_outside[0].fillna('')\n",
    "    matches_inside = conditions['de_asciied_unmapped_conditions'].str.extract(pattern_inside)\n",
    "    conditions['de_asciied_conditions_split_2'] = matches_inside[0].fillna('')\n",
    "    \n",
    "    metamap_version = [int(s) for s in re.findall(r'\\d+', metamap_dirs.get('metamap_bin_dir'))]\n",
    "    \n",
    "    # see MetaMap Usage instructions: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/MM_2016_Usage.pdf\n",
    "#     condition_args = ['--sldi -I -C -J acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf -z -i -f']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    condition_semantic_type_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    params = {\"restrict_to_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False} # strict_model and relaxed_model are presumably opposites? relaxed_model = True is what I want, but that option appears to be broken in Pymetamap (returns no results when used). Using strict_model = False instead...\n",
    "\n",
    "    # prep output file of Metamap results\n",
    "    date = flag_and_path[\"date_string\"]\n",
    "    filename = f\"metamap_output_{date}.tsv\"\n",
    "    metamap_output = open(filename, 'w+', newline='')\n",
    "    col_names = ['term_type', 'clin_trial_term','metamap_preferred_name', 'metamap_cui', 'metamap_score', 'metamap_semantic_type']\n",
    "    csv_writer = csv.writer(metamap_output, delimiter='\\t')\n",
    "    csv_writer.writerow(col_names)\n",
    "    \n",
    "    if metamap_version[0] >= 20:\n",
    "        print(\"MetaMap version >= 2020, conduct mapping on original terms\")\n",
    "#         mm_conditions = run_parallel_threads_mm(conditions[\"original_condition_split_1\"].tolist(), params)\n",
    "        mm_conditions = parallelize_metamap(conditions[\"original_condition_split_1\"].tolist(), params, \"condition\", flag_and_path, csv_writer)\n",
    "    else:\n",
    "        print(\"MetaMap version < 2020, conduct mapping on terms after removing ascii characters\")\n",
    "#         mm_conditions = run_parallel_threads_mm(conditions[\"de_asciied_conditions_split_1\"].tolist(), params)\n",
    "        parallelize_metamap(conditions[\"original_condition_split_1\"].tolist(), params, \"condition\", flag_and_path, csv_writer)\n",
    "    stop_metamap_servers(metamap_dirs) # stop the MetaMap servers\n",
    "\n",
    "#     return mm_conditions   \n",
    "    \n",
    "\n",
    "\n",
    "# open(\"metamap_output_().tsv\".format(flag_and_path[\"date_string\"]), 'w+', newline='')\n",
    "#     col_names = ['term_type', 'clin_trial_term','metamap_preferred_name', 'metamap_cui', 'metamap_score', 'metamap_semantic_type']\n",
    "#     csv_writer = csv.writer(metamap_output, delimiter='\\t')\n",
    "#     csv_writer.writerow(col_names)\n",
    "    \n",
    "#     csv_writer.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"Using UMLS MetaMap to get more mappings for conditions. MetaMap returns mappings, CUIs, and semantic type of mapping.\")\n",
    "#     unmapped_conditions = ct_terms[\"unmapped_conditions\"]\n",
    "#     conditions_unmapped_chunked = split_list_by_char_lim(unmapped_conditions)\n",
    "#     # see MetaMap Usage instructions: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/MM_2016_Usage.pdf\n",
    "#     # removing sosy semantic type (sign or symptom) - often get MetaMap matches to the sign or symptom instead of the full disease...for example, will get back \"exercise-induced\" instead of \"immune dysfunction\" for \"exercise-induced immune dysfunction\" bc it matches the descriptive quality \"exercise-induced\" is matched on \n",
    "#     condition_args = ['--sldi -I -C -J acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,sosy -z -i -f']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "#     mm_conditions = run_parallel_threads_mm(conditions_unmapped_chunked, condition_args)\n",
    "#     flattened_mm_conditions = {key: [item for sublist in value for item in sublist] for key, value in mm_conditions.items()}\n",
    "#     mm_conditions_df = pd.DataFrame({\"condition_input\": list(flattened_mm_conditions.keys()),\n",
    "#                                      \"condition_CURIE_id\": [value[0] for value in flattened_mm_conditions.values()],\n",
    "#                                      \"condition_CURIE_name\": [value[1] for value in flattened_mm_conditions.values()],\n",
    "#                                      \"condition_semantic_type\": [value[-1] for value in flattened_mm_conditions.values()],\n",
    "#                                      \"source\": \"MetaMap via UMLS, term and CURIE\"})\n",
    "    \n",
    "#     mm_conditions_df[['condition_CURIE_name_1', 'condition_CURIE_name_2']] = mm_conditions_df['condition_CURIE_name'].str.extract(r'^(.*?)\\s*\\((.*?)\\)$').fillna('NA') # \n",
    "\n",
    "#     sort_ratio = np.vectorize(get_token_sort_ratio)\n",
    "#     set_ratio = np.vectorize(get_token_set_ratio)\n",
    "#     sim_score = np.vectorize(get_similarity_score)\n",
    "\n",
    "#     # many MetaMap terms are returned as \"term (term)\". For example, \"Nonessential Amino Acid (Nonessential amino acid)\". This repetition messes up the sort ratio and sim score, so we extract the substrings out of the parenthesis to conduct scoring on those\n",
    "#     mm_conditions_scored = mm_conditions_df.copy()\n",
    "#     mm_conditions_scored[\"sort_ratio\"] = sort_ratio(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name\"]].values) # generate fuzzy scores based between original and MeSH term\n",
    "#     mm_conditions_scored[\"sim_score\"] = sim_score(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name\"]].values)\n",
    "\n",
    "#     mm_conditions_scored[\"sort_ratio_1\"] = sort_ratio(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name_1\"]].values) # generate fuzzy scores based between original and MetaMap term\n",
    "#     mm_conditions_scored[\"sim_score_1\"] = sim_score(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name_1\"]].values)\n",
    "\n",
    "#     mm_conditions_scored[\"sort_ratio_2\"] = sort_ratio(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name_2\"]].values) # generate fuzzy scores based between original and MetaMap term\n",
    "#     mm_conditions_scored[\"sim_score_2\"] = sim_score(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name_2\"]].values)\n",
    "\n",
    "#     mm_conditions_scored_thresholded = mm_conditions_scored.copy() \n",
    "    \n",
    "#     mm_conditions_scored[\"sort_ratio\"] = sort_ratio(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name\"]].values) # generate fuzzy scores based between original and MetaMap term\n",
    "#     mm_conditions_scored[\"sim_score\"] = sim_score(mm_conditions_scored[[\"condition_input\"]].values, mm_conditions_scored[[\"condition_CURIE_name\"]].values)\n",
    "#     mm_conditions_scored_thresholded = mm_conditions_scored.copy() \n",
    "#     mm_conditions_scored_thresholded = mm_conditions_scored_thresholded[(mm_conditions_scored_thresholded['sim_score'] > 88) |\n",
    "#                                                                         (mm_conditions_scored_thresholded['sort_ratio'] > 88) |\n",
    "#                                                                         (mm_conditions_scored_thresholded['sim_score_1'] > 88) |\n",
    "#                                                                         (mm_conditions_scored_thresholded['sort_ratio_1'] > 88) |\n",
    "#                                                                         (mm_conditions_scored_thresholded['sim_score_2'] > 88) |\n",
    "#                                                                         (mm_conditions_scored_thresholded['sort_ratio_2'] > 88)]\n",
    "    \n",
    "#     print(\"Number of unique conditions that are mapped after using MetaMap and similarity and ratio score thresholds of 88: {}\".format(mm_conditions_scored_thresholded.shape[0]))\n",
    "    \n",
    "#     mm_conditions_scored_thresholded = mm_conditions_scored_thresholded.drop(['condition_CURIE_name_1',\n",
    "#                                                                               'condition_CURIE_name_2',\n",
    "#                                                                               'sort_ratio',\n",
    "#                                                                               'sim_score',\n",
    "#                                                                               'sort_ratio_1',\n",
    "#                                                                               'sim_score_1',\n",
    "#                                                                               'sort_ratio_2',\n",
    "#                                                                               'sim_score_2'], axis=1)\n",
    "#     previously_mapped = ct_terms[\"mapped_conditions\"]\n",
    "#     combined_mapped_conditions = pd.concat([previously_mapped, mm_conditions_scored_thresholded], ignore_index=True) # get dataframe of combined previously mapped conditions and additional MetaMapped interventions that passed threshold scoring\n",
    "\n",
    "#     conditions = df_dict[\"conditions\"]\n",
    "#     all_conditions_list = conditions[\"downcase_name\"].values.tolist()\n",
    "#     all_conditions_list = list(set(all_conditions_list))\n",
    "#     unmapped_conditions = list(set(all_conditions_list)-set(list(combined_mapped_conditions.condition_input.values)))\n",
    "#     print(\"Number of unique conditions that are unmapped after using MetaMap and similarity and ratio score thresholds of 88: {}\".format(len(unmapped_conditions)))\n",
    "          \n",
    "#     # -------    INTERVENTIONS    ------- #\n",
    "#     print(\"Using UMLS MetaMap to get more mappings for interventions. MetaMap returns mappings, CUIs, and semantic type of mapping.\")\n",
    "#     unmapped_interventions = ct_terms[\"unmapped_interventions\"]\n",
    "#     interventions_unmapped_chunked = split_list_by_char_lim(unmapped_interventions)\n",
    "#     # see MetaMap Usage instructions: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/MM_2016_Usage.pdf\n",
    "#     # removing sosy semantic type (sign or symptom) - often get MetaMap matches to the sign or symptom instead of the full disease...for example, will get back \"exercise-induced\" instead of \"immune dysfunction\" for \"exercise-induced immune dysfunction\" bc it matches the descriptive quality \"exercise-induced\" is matched on \n",
    "#     intervention_args = ['--sldi -I -C -k acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,sosy -z -i -f']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\") (I used inverse of semantic terms picked for conditions here)\n",
    "#     mm_interventions = run_parallel_threads_mm(interventions_unmapped_chunked, intervention_args)\n",
    "#     flattened_mm_interventions = {key: [item for sublist in value for item in sublist] for key, value in mm_interventions.items()}\n",
    "#     mm_interventions_df = pd.DataFrame({\"intervention_input\": list(flattened_mm_interventions.keys()),\n",
    "#                                         \"intervention_CURIE_id\": [value[0] for value in flattened_mm_interventions.values()],\n",
    "#                                         \"intervention_CURIE_name\": [value[1] for value in flattened_mm_interventions.values()],\n",
    "#                                         \"intervention_semantic_type\": [value[-1] for value in flattened_mm_interventions.values()],\n",
    "#                                         \"source\": \"MetaMap via UMLS, term and CURIE\"})\n",
    "\n",
    "#     mm_interventions_df[['intervention_CURIE_name_1', 'intervention_CURIE_name_2']] = mm_interventions_df['intervention_CURIE_name'].str.extract(r'^(.*?)\\s*\\((.*?)\\)$').fillna('NA') # \n",
    "\n",
    "#     sort_ratio = np.vectorize(get_token_sort_ratio)\n",
    "#     set_ratio = np.vectorize(get_token_set_ratio)\n",
    "#     sim_score = np.vectorize(get_similarity_score)\n",
    "\n",
    "#     # many MetaMap terms are returned as \"term (term)\". For example, \"Nonessential Amino Acid (Nonessential amino acid)\". This repetition messes up the sort ratio and sim score, so we extract the substrings out of the parenthesis to conduct scoring on those\n",
    "#     mm_interventions_scored = mm_interventions_df.copy()\n",
    "#     mm_interventions_scored[\"sort_ratio\"] = sort_ratio(mm_interventions_scored[[\"intervention_input\"]].values, mm_interventions_scored[[\"intervention_CURIE_name\"]].values) # generate fuzzy scores based between original and MeSH term\n",
    "#     mm_interventions_scored[\"sim_score\"] = sim_score(mm_interventions_scored[[\"intervention_input\"]].values, mm_interventions_scored[[\"intervention_CURIE_name\"]].values)\n",
    "\n",
    "#     mm_interventions_scored[\"sort_ratio_1\"] = sort_ratio(mm_interventions_scored[[\"intervention_input\"]].values, mm_interventions_scored[[\"intervention_CURIE_name_1\"]].values) # generate fuzzy scores based between original and MetaMap term\n",
    "#     mm_interventions_scored[\"sim_score_1\"] = sim_score(mm_interventions_scored[[\"intervention_input\"]].values, mm_interventions_scored[[\"intervention_CURIE_name_1\"]].values)\n",
    "\n",
    "#     mm_interventions_scored[\"sort_ratio_2\"] = sort_ratio(mm_interventions_scored[[\"intervention_input\"]].values, mm_interventions_scored[[\"intervention_CURIE_name_2\"]].values) # generate fuzzy scores based between original and MetaMap term\n",
    "#     mm_interventions_scored[\"sim_score_2\"] = sim_score(mm_interventions_scored[[\"intervention_input\"]].values, mm_interventions_scored[[\"intervention_CURIE_name_2\"]].values)\n",
    "\n",
    "#     mm_interventions_scored_thresholded = mm_interventions_scored.copy() \n",
    "#     mm_interventions_scored_thresholded = mm_interventions_scored_thresholded[(mm_interventions_scored_thresholded['sim_score'] > 88) |\n",
    "#                                                                               (mm_interventions_scored_thresholded['sort_ratio'] > 88) |\n",
    "#                                                                               (mm_interventions_scored_thresholded['sim_score_1'] > 88) |\n",
    "#                                                                               (mm_interventions_scored_thresholded['sort_ratio_1'] > 88) |\n",
    "#                                                                               (mm_interventions_scored_thresholded['sim_score_2'] > 88) |\n",
    "#                                                                               (mm_interventions_scored_thresholded['sort_ratio_2'] > 88)]\n",
    "    \n",
    "#     print(\"Number of unique interventions that are mapped after using MetaMap and similarity and ratio score thresholds of 88: {}\".format(mm_interventions_scored_thresholded.shape[0]))\n",
    "\n",
    "#     mm_interventions_scored_thresholded = mm_interventions_scored_thresholded.drop(['intervention_CURIE_name_1',\n",
    "#                                                                                     'intervention_CURIE_name_2',\n",
    "#                                                                                     'sort_ratio',\n",
    "#                                                                                     'sim_score',\n",
    "#                                                                                     'sort_ratio_1',\n",
    "#                                                                                     'sim_score_1',\n",
    "#                                                                                     'sort_ratio_2',\n",
    "#                                                                                     'sim_score_2'], axis=1)\n",
    "#     previously_mapped = ct_terms[\"mapped_interventions\"]\n",
    "#     combined_mapped_interventions = pd.concat([previously_mapped, mm_interventions_scored_thresholded], ignore_index=True) # get dataframe of combined previously mapped interventions and additional MetaMapped interventions that passed threshold scoring\n",
    "#     interventions = df_dict[\"interventions\"]\n",
    "#     all_interventions_list = interventions[\"downcase_name\"].values.tolist()\n",
    "#     all_interventions_list = list(set(all_interventions_list))\n",
    "#     unmapped_interventions = list(set(all_interventions_list)-set(list(combined_mapped_interventions.intervention_input.values)))\n",
    "#     print(\"Number of unique interventions that are unmapped after using MetaMap and similarity and ratio score thresholds of 88: {}\".format(len(unmapped_interventions)))\n",
    "#     ct_terms = {'mapped_conditions': combined_mapped_conditions,\n",
    "#                 'unmapped_conditions': unmapped_conditions,\n",
    "#                 'mapped_interventions': combined_mapped_interventions,\n",
    "#                 'unmapped_interventions': unmapped_interventions,\n",
    "#                 'all_metamapped_conditions': mm_conditions_df,\n",
    "#                 'all_metamapped_interventions': mm_interventions_df}\n",
    "\n",
    "\n",
    "#     return ct_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dc9c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output all results to TSVs\n",
    "def compile_and_output(df_dict, ct_terms, remaining_unmapped_possible):\n",
    "    print(\"\\n\")\n",
    "    print(\"#   -------- -------- -------- --------  \")\n",
    "    print(\"Final Tallies:\")\n",
    "    print(\"Total # of conditions mapped: {}\".format(ct_terms[\"mapped_conditions\"].shape[0]))\n",
    "    print(\"Total # of interventions mapped: {}\".format(ct_terms[\"mapped_interventions\"].shape[0]))\n",
    "    print(\"Total # of conditions unmapped or not mapped: {}\".format(len(ct_terms[\"unmapped_conditions\"])))\n",
    "    print(\"Total # of interventions unmapped or not mapped: {}\".format(len(ct_terms[\"unmapped_interventions\"])))    \n",
    "    # How many Clinical Trials are there? Well, it's different depending on the Conditions or Interventions dataframes...\n",
    "    conditions_nctids = len(df_dict[\"conditions\"].nct_id.unique())\n",
    "    interventions_nctids = len(df_dict[\"interventions\"].nct_id.unique())\n",
    "    print(\"Number of Clinical Trials NCITs in Conditions table: {}\".format(conditions_nctids))      \n",
    "    print(\"Number of Clinical Trials NCITs in Interventions table: {}\".format(interventions_nctids))\n",
    "    print(\"#   -------- -------- -------- --------  \")\n",
    "\n",
    "    \"\"\" create tables of unused MeSH and MetaMap CURIEs that could be used for unmapped Conditions and Interventions \"\"\"\n",
    "    # -------    CONDITIONS    ------- #\n",
    "    all_conditions = df_dict[\"conditions\"][[\"nct_id\", \"downcase_name\"]]\n",
    "    conditions_mesh = pd.merge(all_conditions, \n",
    "                               remaining_unmapped_possible[\"mesh_conditions_per_study\"],\n",
    "                               how='left',\n",
    "                               left_on=['nct_id'],\n",
    "                               right_on = ['nct_id'])\n",
    "    \n",
    "    metamap_possibilities = remaining_unmapped_possible[\"all_metamapped_conditions\"][[\"condition_input\", \"condition_CURIE_id\", \"condition_CURIE_name\", \"condition_semantic_type\"]]\n",
    "    conditions_mesh_metamap = pd.merge(conditions_mesh, \n",
    "                                       metamap_possibilities,\n",
    "                                       how='left',\n",
    "                                       left_on=['downcase_name'],\n",
    "                                       right_on = ['condition_input'])\n",
    "    \n",
    "    unmapped_conditions_possible_terms = conditions_mesh_metamap[conditions_mesh_metamap['downcase_name'].isin(ct_terms[\"unmapped_conditions\"])]\n",
    "    unmapped_conditions_possible_terms = unmapped_conditions_possible_terms.drop('condition_input', axis=1) # drop the redundant column now\n",
    "    \n",
    "    # -------    INTERVENTIONS    ------- #\n",
    "    all_interventions = df_dict[\"interventions\"][[\"nct_id\", \"downcase_name\"]]\n",
    "    interventions_mesh = pd.merge(all_interventions, \n",
    "                               remaining_unmapped_possible[\"mesh_interventions_per_study\"],\n",
    "                               how='left',\n",
    "                               left_on=['nct_id'],\n",
    "                               right_on = ['nct_id'])\n",
    "    \n",
    "    metamap_possibilities = remaining_unmapped_possible[\"all_metamapped_interventions\"][[\"intervention_input\", \"intervention_CURIE_id\", \"intervention_CURIE_name\", \"intervention_semantic_type\"]]\n",
    "    interventions_mesh_metamap = pd.merge(interventions_mesh, \n",
    "                                       metamap_possibilities,\n",
    "                                       how='left',\n",
    "                                       left_on=['downcase_name'],\n",
    "                                       right_on = ['intervention_input'])\n",
    "    \n",
    "    unmapped_interventions_possible_terms = interventions_mesh_metamap[interventions_mesh_metamap['downcase_name'].isin(ct_terms[\"unmapped_interventions\"])]\n",
    "    unmapped_interventions_possible_terms = unmapped_interventions_possible_terms.drop('intervention_input', axis=1) # drop the redundant column now\n",
    "          \n",
    "        \n",
    "    \"\"\"   Output all to TSVs   \"\"\"    \n",
    "    pd.Series(ct_terms[\"unmapped_conditions\"]).to_csv('unmapped_conditions.tsv', sep=\"\\t\", index=False, header=False) # convert the list to a pandas series, then output to TSV\n",
    "    pd.Series(ct_terms[\"unmapped_interventions\"]).to_csv('unmapped_interventions.tsv', sep=\"\\t\", index=False, header=False) # convert the list to a pandas series, then output to TSV\n",
    "    ct_terms[\"mapped_conditions\"].to_csv('mapped_conditions.tsv', sep=\"\\t\", index=False)\n",
    "    ct_terms[\"mapped_interventions\"].to_csv('mapped_interventions.tsv', sep=\"\\t\", index=False)\n",
    "    unmapped_conditions_possible_terms.to_csv('unmapped_conditions_possible_mappings.tsv', sep=\"\\t\", index=False)\n",
    "    unmapped_interventions_possible_terms.to_csv('unmapped_interventions_possible_mappings.tsv', sep=\"\\t\", index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_or_prod():\n",
    "#     print(\"The test run of this code performs the construction of the KG on a subset of 200 Conditions and 200 Interventions from Clinical Trials.\\n\")\n",
    "#     test_or_prod = input(\"Is this a test run or the production of a new version of the KG? Write T for test, or P for production: \")\n",
    "#     if test_or_prod == \"T\":\n",
    "#         flag_and_path = get_raw_ct_data() # uncomment for production\n",
    "#         flag_and_path[\"term_program_flag\"] = False\n",
    "#         run_ETL_mapping(flag_and_path)\n",
    "#     elif test_or_prod == \"P\":\n",
    "#         flag_and_path = get_raw_ct_data() \n",
    "#         run_ETL_mapping(flag_and_path)\n",
    "#     else:\n",
    "#         print(\"Bad input\")\n",
    "#         sys.exit(0)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ecb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_ETL_mapping(flag_and_path):\n",
    "#     df_dict = read_raw_ct_data(flag_and_path)\n",
    "#     ct_terms = exact_match_mesh(df_dict)\n",
    "#     ct_terms = inexact_match_mesh(df_dict, ct_terms)\n",
    "\n",
    "#     # pull the available MeSH terms per study out of the returned ct_terms dict \n",
    "#     mesh_conditions_per_study = ct_terms[\"mesh_conditions_per_study\"]\n",
    "#     mesh_interventions_per_study = ct_terms[\"mesh_interventions_per_study\"]\n",
    "\n",
    "#     ct_terms = term_list_to_nr(df_dict, ct_terms)\n",
    "#     ct_terms = term_list_to_mm(df_dict, ct_terms)\n",
    "\n",
    "#     # pull the available UMLS terms per study out of the returned ct_terms dict \n",
    "#     all_metamapped_conditions = ct_terms[\"all_metamapped_conditions\"]\n",
    "#     all_metamapped_interventions = ct_terms[\"all_metamapped_interventions\"]\n",
    "\n",
    "#     remaining_unmapped_possible = {\"mesh_conditions_per_study\": mesh_conditions_per_study,\n",
    "#                                    \"mesh_interventions_per_study\": mesh_interventions_per_study,\n",
    "#                                    \"all_metamapped_conditions\": all_metamapped_conditions,\n",
    "#                                    \"all_metamapped_interventions\": all_metamapped_interventions}\n",
    "#     compile_and_output(df_dict, ct_terms, remaining_unmapped_possible)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eebe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e73916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb512b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff65fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9e613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05df30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e8218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00d094e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['infarction, myocardial', 'aneurysm', 'diabetes', 'common cold', 'fracture', 'juice blend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8378d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_metamap_servers(metamap_dirs)\n",
    "mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "condition_semtype_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "\n",
    "params = {\"restrict_to_sts\":condition_semtype_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"relaxed_model\":True, \"strict_model\":False}\n",
    "\n",
    "terms = ['infarction, myocardial', 'aneurysm', 'diabetes', 'common cold', 'fracture', 'juice blend']\n",
    "\n",
    "concepts,error = mm.extract_concepts(terms,\n",
    "                                     term_processing = params[\"term_processing\"],\n",
    "                                     ignore_word_order = params[\"ignore_word_order\"],\n",
    "#                                      relaxed_model = params[\"relaxed_model\"]\n",
    "#                                      restrict_to_sts=params[\"restrict_to_sts\"]\n",
    "                                    strict_model = params[\"strict_model\"]\n",
    "                                    )\n",
    "for concept in concepts:\n",
    "    print(concept)\n",
    "    print(\"\\n\")\n",
    "stop_metamap_servers(metamap_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c425ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'term_program_flag': False,\n",
       " 'data_extracted_path': '/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/08_21_2023_extracted',\n",
       " 'date_string': '08_21_2023'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_and_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc3c1715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using UMLS MetaMap to get mappings for conditions. MetaMap returns mappings, CUIs, and semantic type of mapping.\n",
      "MetaMap version < 2020, conduct mapping on terms after removing ascii characters\n"
     ]
    }
   ],
   "source": [
    "# flag_and_path = get_raw_ct_data() # uncomment for production\n",
    "flag_and_path = {'term_program_flag': False,\n",
    "                 'data_extracted_path': '/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/08_21_2023_extracted',\n",
    "                 'date_string':'08_21_2023'} # comment for production\n",
    "metamap_dirs = check_os()\n",
    "df_dict = read_raw_ct_data(flag_and_path)\n",
    "# ct_terms = exact_match_mesh(df_dict)\n",
    "# ct_terms = inexact_match_mesh(df_dict, ct_terms)\n",
    "\n",
    "# # pull the available MeSH terms per study out of the returned ct_terms dict \n",
    "# mesh_conditions_per_study = ct_terms[\"mesh_conditions_per_study\"]\n",
    "# mesh_interventions_per_study = ct_terms[\"mesh_interventions_per_study\"]\n",
    "\n",
    "# ct_terms = term_list_to_nr(df_dict, ct_terms)\n",
    "# ct_terms = term_list_to_mm(df_dict, flag_and_path)\n",
    "term_list_to_mm(df_dict, flag_and_path)\n",
    "\n",
    "# # pull the available UMLS terms per study out of the returned ct_terms dict \n",
    "# all_metamapped_conditions = ct_terms[\"all_metamapped_conditions\"]\n",
    "# all_metamapped_interventions = ct_terms[\"all_metamapped_interventions\"]\n",
    "\n",
    "# remaining_unmapped_possible = {\"mesh_conditions_per_study\": mesh_conditions_per_study,\n",
    "#                                \"mesh_interventions_per_study\": mesh_interventions_per_study,\n",
    "#                                \"all_metamapped_conditions\": all_metamapped_conditions,\n",
    "#                                \"all_metamapped_interventions\": all_metamapped_interventions}\n",
    "# compile_and_output(df_dict, ct_terms, remaining_unmapped_possible)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d58f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_hms(seconds):\n",
    "\n",
    "    \"\"\" converts the elapsed or run_time to hours, min, sec \"\"\"\n",
    "    hours = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return hours, minutes, seconds\n",
    "\n",
    "current = dt.datetime.now()\n",
    "ts = dt.datetime.timestamp(current)\n",
    "d = dt.datetime.fromtimestamp(ts)\n",
    "str_date_time = d.strftime(\"%d-%m-%Y, %H:%M:%S\")\n",
    "print(\"Timestamp of script start: {}\".format(str_date_time))\n",
    "\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "print(f\"Runtime: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411fde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_unmapped_possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
