{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da527b7e-2d30-4660-b6ee-1a63bc9df48f",
   "metadata": {},
   "source": [
    "### THIS SCRIPT USES MetaMap to try and map the bulk of terms, and Name Resolver to pick up what's left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730291b8-7f12-4e72-bfa6-4c7ae33ae738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display cells to maximum width \n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "\n",
    "# lets you preint multiple outputs per cell, not just last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b0f433-c7bb-4b98-aa7b-1d1e6ad1e3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import time\n",
    "from time import sleep\n",
    "# import concurrent\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import pathlib\n",
    "import configparser\n",
    "import sys\n",
    "import urllib\n",
    "import zipfile\n",
    "import csv\n",
    "sys.path.insert(0, '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/pymetamap-master')\n",
    "from pymetamap import MetaMap  # https://github.com/AnthonyMRios/pymetamap/blob/master/pymetamap/SubprocessBackend.py\n",
    "from pandas import ExcelWriter\n",
    "import ast\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import shlex\n",
    "from collections import Counter\n",
    "\n",
    "# %pip install thefuzz\n",
    "# %pip install levenshtein\n",
    "# %pip install xlsxwriter\n",
    "# %pip install ratelimit\n",
    "\n",
    "from thefuzz import fuzz # fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d4d831-06e5-4439-920e-b6495d81adc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_sort_ratio(str1, str2):\n",
    "    \"\"\" fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python \"\"\"\n",
    "    try:\n",
    "        return fuzz.token_sort_ratio(str1, str2)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_token_set_ratio(str1, str2):\n",
    "    \"\"\" fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python \"\"\"\n",
    "    try:\n",
    "        return fuzz.token_set_ratio(str1, str2)\n",
    "    except:\n",
    "        return None  \n",
    "\n",
    "def get_similarity_score(str1, str2):\n",
    "    \"\"\" fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python \"\"\"\n",
    "    try:\n",
    "        return fuzz.ratio(str1, str2)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def convert_seconds_to_hms(seconds):\n",
    "    \"\"\" converts the elapsed time or runtime to hours, min, sec \"\"\"\n",
    "    hours = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return hours, minutes, seconds\n",
    "\n",
    "def de_ascii_er(text):\n",
    "    non_ascii = \"[^\\x00-\\x7F]\"\n",
    "    pattern = re.compile(r\"[^\\x00-\\x7F]\")\n",
    "    non_ascii_text = re.sub(pattern, ' ', text)\n",
    "    return non_ascii_text\n",
    "\n",
    "def start_metamap_servers(metamap_dirs):\n",
    "    global metamap_pos_server_dir\n",
    "    global metamap_wsd_server_dir\n",
    "    metamap_pos_server_dir = 'bin/skrmedpostctl' # Part of speech tagger\n",
    "    metamap_wsd_server_dir = 'bin/wsdserverctl' # Word sense disambiguation \n",
    "    \n",
    "    metamap_executable_path_pos = os.path.join(metamap_dirs['metamap_base_dir'], metamap_pos_server_dir)\n",
    "    metamap_executable_path_wsd = os.path.join(metamap_dirs['metamap_base_dir'], metamap_wsd_server_dir)\n",
    "    command_pos = [metamap_executable_path_pos, 'start']\n",
    "    command_wsd = [metamap_executable_path_wsd, 'start']\n",
    "\n",
    "    # Start servers, with open portion redirects output of metamap server printing output to NULL\n",
    "    with open(os.devnull, \"w\") as fnull:\n",
    "        result_post = subprocess.call(command_pos, stdout = fnull, stderr = fnull)\n",
    "        result_wsd = subprocess.call(command_wsd, stdout = fnull, stderr = fnull)\n",
    "    sleep(5)\n",
    "\n",
    "def stop_metamap_servers(metamap_dirs):\n",
    "    metamap_executable_path_pos = os.path.join(metamap_dirs['metamap_base_dir'], metamap_pos_server_dir)\n",
    "    metamap_executable_path_wsd = os.path.join(metamap_dirs['metamap_base_dir'], metamap_wsd_server_dir)\n",
    "    command_pos = [metamap_executable_path_pos, 'stop']\n",
    "    command_wsd = [metamap_executable_path_wsd, 'stop']\n",
    "    \n",
    "    # Stop servers, with open portion redirects output of metamap server printing output to NULL\n",
    "    with open(os.devnull, \"w\") as fnull:\n",
    "        result_post = subprocess.call(command_pos, stdout = fnull, stderr = fnull)\n",
    "        result_wsd = subprocess.call(command_wsd, stdout = fnull, stderr = fnull)\n",
    "    sleep(2)  \n",
    "    \n",
    "def add_mappings_to_cache(flag_and_path):\n",
    "    relevant_date = flag_and_path[\"date_string\"]   # get date of bulk download of clinical trial data\n",
    "    with open(\"metamapped_terms_cache.tsv\", 'a+', encoding=\"utf-8\") as cache:\n",
    "        with open(f\"{relevant_date}_metamap_output.tsv\", 'r', encoding=\"utf-8\", errors='ignore') as new_metamapped_terms:\n",
    "            # Read the first line from new_metamapped_terms to move the cursor\n",
    "            line = new_metamapped_terms.readline()\n",
    "\n",
    "            # Move the cursor to the position after the first line\n",
    "            while line:\n",
    "                line = new_metamapped_terms.readline()\n",
    "                if line:\n",
    "                    # Append the line to file_1\n",
    "                    cache.write(line)\n",
    "    \"\"\" Remove duplicate rows from cache \"\"\"\n",
    "    cache = pd.read_csv(\"metamapped_terms_cache.tsv\", sep='\\t', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "    cache = cache.drop_duplicates()\n",
    "    cache.to_csv('metamapped_terms_cache.tsv', sep=\"\\t\", index=False, header=True) # output deduplicated cache terms to TSV\n",
    "\n",
    "def add_manually_selected_terms_to_cache():\n",
    "    # -----     ------     GENERATE MANUALLY SELECTED CACHE     -----     ------  #\n",
    "    try:\n",
    "        #  --- --- --   CONDITIONS     --- --- --   #\n",
    "        files = glob.glob(\"*.xlsx\")\n",
    "        conditions_manselected_files = [i for i in files if \"conditions_manual_review\" in i if not i.startswith(\"~\")][0]  \n",
    "        conditions_manselected = pd.read_excel(conditions_manselected_files)\n",
    "        conditions_manselected.name.ffill(inplace=True)\n",
    "        conditions_manselected.orig_con.ffill(inplace=True)\n",
    "        conditions_manselected = conditions_manselected[~conditions_manselected['manually_selected_CURIE'].isnull()] # check if the conditions got mapped to any CURIEs\n",
    "        conditions_manselected.drop([\"curie_info\"], axis = 1, inplace = True)\n",
    "        conditions_manselected.rename(columns = {'name':'original_clin_trial_term', 'orig_con':'modified_clin_trial_term'}, inplace = True)\n",
    "\n",
    "        with open('conditions_manually_selected_cache.tsv', 'a') as output:\n",
    "            conditions_manselected.to_csv(output, mode='a',sep=\"\\t\", index=False, header=output.tell()==0)\n",
    "        \"\"\" Remove duplicate rows from cache \"\"\"\n",
    "        cache = pd.read_csv(\"conditions_manually_selected_cache.tsv\", sep='\\t', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "        cache = cache.drop_duplicates()\n",
    "        cache.to_csv('conditions_manually_selected_cache.tsv', sep=\"\\t\", index=False, header=True) # output deduplicated cache terms to TSV\n",
    "\n",
    "        #  --- --- --   INTERVENTIONS and Alternate INTERVENTIONS   --- --- --   #\n",
    "        files = glob.glob(\"*.xlsx\")\n",
    "        interventions_manselected_files = [i for i in files if \"interventions_manual_review\" in i if not i.startswith(\"~\")][0]  \n",
    "        interventions_manselected = pd.read_excel(interventions_manselected_files)\n",
    "        interventions_manselected.name.ffill(inplace=True)\n",
    "        interventions_manselected.orig_int.ffill(inplace=True)\n",
    "        interventions_manselected = interventions_manselected[~interventions_manselected['manually_selected_CURIE'].isnull()] # check if the conditions got mapped to any CURIEs\n",
    "        interventions_manselected.drop([\"curie_info\", \"description\"], axis = 1, inplace = True)\n",
    "        interventions_manselected.rename(columns = {'name':'original_clin_trial_term', 'orig_int':'modified_clin_trial_term'}, inplace = True)\n",
    "\n",
    "        with open('interventions_manually_selected_cache.tsv', 'a') as output:\n",
    "            interventions_manselected.to_csv(output, mode='a',sep=\"\\t\", index=False, header=output.tell()==0)\n",
    "        \"\"\" Remove duplicate rows from cache \"\"\"\n",
    "        cache = pd.read_csv(\"interventions_manually_selected_cache.tsv\", sep='\\t', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "        cache = cache.drop_duplicates()\n",
    "        cache.to_csv('interventions_manually_selected_cache.tsv', sep=\"\\t\", index=False, header=True) # output deduplicated cache terms to TSV\n",
    "    except:\n",
    "        print(\"No terms in manual select column; either column is empty or bug. Proceeding without them\")\n",
    "        \n",
    "def check_os():\n",
    "    if \"linux\" in sys.platform:\n",
    "        print(\"Linux platform detected\")\n",
    "        metamap_base_dir = \"{}/metamap/\".format(pathlib.Path.cwd().parents[0])\n",
    "        metamap_bin_dir = 'bin/metamap20'\n",
    "    else:\n",
    "        metamap_base_dir = '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/public_mm/' # for running on local\n",
    "        metamap_bin_dir = 'bin/metamap18'\n",
    "        \n",
    "    return {\"metamap_base_dir\":metamap_base_dir, \"metamap_bin_dir\":metamap_bin_dir}  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6746b051-2524-4d93-ad30-69e7fcd225e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_raw_ct_data():\n",
    "    term_program_flag = True\n",
    "    global data_dir\n",
    "    global data_extracted\n",
    "    \n",
    "    try:\n",
    "        # get all the links and associated dates of upload into a dict called date_link\n",
    "        url_all = \"https://aact.ctti-clinicaltrials.org/download\"\n",
    "        response = requests.get(url_all)\n",
    "        soup = BeautifulSoup(response.text, features=\"lxml\")\n",
    "        body = soup.find_all('option') #Find all\n",
    "        date_link = {}\n",
    "        for el in body:\n",
    "            tags = el.find('a')\n",
    "            try:\n",
    "                zip_name = tags.contents[0].split()[0]\n",
    "                date = zip_name.split(\"_\")[0]\n",
    "                date = dt.datetime.strptime(date, '%Y%m%d').date()\n",
    "                date_link[date] = tags.get('href')\n",
    "            except:\n",
    "                pass\n",
    "        latest_file_date = max(date_link.keys())   # get the date of the latest upload\n",
    "        url = date_link[latest_file_date]   # get the corresponding download link of the latest upload so we can download the raw data\n",
    "        date_string = latest_file_date.strftime(\"%m_%d_%Y\")\n",
    "        data_dir = \"{}/data\".format(pathlib.Path.cwd())\n",
    "        data_extracted = data_dir + \"/{}_extracted\".format(date_string)\n",
    "        data_path = \"{}/{}_pipe-delimited-export.zip\".format(data_dir, date_string)\n",
    "    except:\n",
    "        print(\"continue\")\n",
    "\n",
    "    if not os.path.exists(data_path):   # if folder containing most recent data doesn't exist, download and extract it into data folder\n",
    "\n",
    "        term_program_flag = False   # flag below for terminating program if latest download exists (KG is assumed up to date)\n",
    "        print(\"Attempting download of Clinical Trial data as of {}\\n\".format(date_string))\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(data_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(\"Finished download of zip\")\n",
    "                with zipfile.ZipFile(data_path, 'r') as download:\n",
    "                    print(\"Unzipping data\")\n",
    "                    download.extractall(data_extracted)\n",
    "        except:\n",
    "            print(\"Failed to scrape AACT for download. Please navigate to https://aact.ctti-clinicaltrials.org/download and manually download zip file.\")\n",
    "            print(\"Please store the downloaded zip in the /data directory. This should be the only item besides the cache file, condition manual review file, and intervention manual review file, in the directory at this time.\")\n",
    "            done = input(\"Type Done when done: \")\n",
    "            if done == \"Done\":\n",
    "                data_dir = \"{}/data\".format(pathlib.Path.cwd())\n",
    "                # list_of_files = glob.glob(data_dir + \"/*\") # get all files in directory\n",
    "                try:\n",
    "                    # latest_file = max(list_of_files, key=os.path.getctime) # get the most recent file in the directory\n",
    "                    pattern = os.path.join(data_dir, \"*.zip\")\n",
    "                    zip_file = glob.glob(pattern) # look for file in directory that ends in \".zip\"\n",
    "                    zip_file = zip_file[0]\n",
    "                    print(\"File found at: \")\n",
    "                    print(zip_file)\n",
    "                    # print(latest_file)\n",
    "                    print(\"Please make sure this the correct zip file from AACT\")\n",
    "                    if not os.path.exists(data_extracted):   # if folder of unzipped data does not exist, unzip\n",
    "                        try:\n",
    "                            with zipfile.ZipFile(zip_file, 'r') as download:\n",
    "                                print(\"Unzipping data into\")\n",
    "                                cttime = os.path.getctime(zip_file)\n",
    "                                date_string = dt.datetime.fromtimestamp(cttime).strftime('%m_%d_%Y')\n",
    "                                data_extracted = data_dir + \"/{}_extracted\".format(date_string)\n",
    "                                print(data_extracted)\n",
    "                                download.extractall(data_extracted)\n",
    "                        except:\n",
    "                            pattern = os.path.join(data_dir, \"*_extracted\")\n",
    "                            extracted_file = glob.glob(pattern) # look for file in directory that ends in \"_extracted\"\n",
    "                            data_extracted = extracted_file[0]\n",
    "                            extracted_name = os.path.basename(os.path.normpath(extracted_file[0]))\n",
    "                            date_string = extracted_name.replace('_extracted', '')\n",
    "                            print(\"Assuming data is already unzipped\")\n",
    "                        \n",
    "                except:\n",
    "                    print(\"Unable to download and extract Clincal Trial data.\")\n",
    "                    print(\"Cannot find pipe-delimited zip in /data folder.\")\n",
    "    else:\n",
    "        print(\"KG is already up to date.\")\n",
    "\n",
    "    return {\"term_program_flag\": term_program_flag, \"data_extracted_path\": data_extracted, \"date_string\": date_string}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4850c49-b00e-422a-805b-137fccb7cd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_raw_ct_data(flag_and_path, subset_size):\n",
    "    if flag_and_path[\"term_program_flag\"]:\n",
    "        print(\"Exiting program. Assuming KG has already been constructed from most recent data dump from AACT.\")\n",
    "        exit()\n",
    "    else:\n",
    "        data_extracted = flag_and_path[\"data_extracted_path\"]\n",
    "        # read in pipe-delimited files \n",
    "        conditions_df = pd.read_csv(data_extracted + '/conditions.txt', sep='|', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "        interventions_df = pd.read_csv(data_extracted + '/interventions.txt', sep='|', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "        interventions_alts_df = pd.read_csv(data_extracted + '/intervention_other_names.txt', sep='|', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "\n",
    "        if subset_size:   # if a subset size is given, we are running this script on a small subset of the dataset\n",
    "            conditions_df = conditions_df.sample(n=subset_size)\n",
    "            interventions_df = interventions_df.sample(n=subset_size)\n",
    "            interventions_alts_df = interventions_alts_df.sample(n=subset_size)\n",
    "    \n",
    "    df_dict = {\"conditions\": conditions_df, \"interventions\": interventions_df, \"interventions_alts\": interventions_alts_df}\n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd612efd-e483-4754-8edd-3dc45fe95e88",
   "metadata": {},
   "source": [
    "# Check against cache, retrieve terms not already mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eddc0c83-10b4-4065-b2bb-1bad9cb0e63a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_against_cache(df_dict):\n",
    "    conditions_list = df_dict['conditions'].name.unique().tolist()\n",
    "    conditions_list = [str(i) for i in conditions_list]\n",
    "    conditions_list = list(set([i.lower() for i in conditions_list]))\n",
    "    \n",
    "    interventions_list = df_dict['interventions'].name.unique().tolist()\n",
    "    interventions_list = [str(i) for i in interventions_list]\n",
    "    interventions_list = list(set([i.lower() for i in interventions_list]))\n",
    "    \n",
    "    interventions_alts_list = df_dict['interventions_alts'].name.unique().tolist()\n",
    "    interventions_alts_list = [str(i) for i in interventions_alts_list]\n",
    "    interventions_alts_list = list(set([i.lower() for i in interventions_alts_list]))\n",
    "    \n",
    "    try:        \n",
    "        cache_df = pd.read_csv(\"mapping_cache.tsv\", sep =\"\\t\", index_col=False, header=0, on_bad_lines = 'warn')\n",
    "        \n",
    "        conditions_cache = cache_df[cache_df[\"term_type\"] == \"condition\"]\n",
    "        conditions_cache = conditions_cache['clintrial_term'].unique().tolist()\n",
    "        conditions_cache = list(set([i.lower() for i in conditions_cache]))\n",
    "        \n",
    "        conditions_new = [x for x in conditions_list if x not in conditions_cache] # find conditions not in the cache (i.g. new conditions to map)\n",
    "        conditions_new = list(filter(None, conditions_new))\n",
    "        conditions_new = [str(i) for i in conditions_new]\n",
    "        \n",
    "        interventions_cache = cache_df[cache_df[\"term_type\"] == \"intervention\"]\n",
    "        interventions_cache = interventions_cache['clintrial_term'].unique().tolist()\n",
    "        interventions_cache = list(set([i.lower() for i in interventions_cache]))\n",
    "        \n",
    "        interventions_new = [x for x in interventions_list if x not in interventions_cache] # find interventions not in the cache (i.g. new interventions to map)\n",
    "        interventions_new = list(filter(None, interventions_new))\n",
    "        interventions_new = [str(i) for i in interventions_new]\n",
    "        \n",
    "        interventions_alts_cache = cache_df[cache_df[\"term_type\"] == \"intervention_alternate\"]\n",
    "        interventions_alts_cache = interventions_alts_cache['clintrial_term'].unique().tolist()\n",
    "        interventions_alts_cache = list(set([i.lower() for i in interventions_alts_cache]))\n",
    "        \n",
    "        interventions_alts_new = [x for x in interventions_alts_list if x not in interventions_alts_cache] # find interventions_alts not in the cache (i.g. new interventions_alts to map)\n",
    "        interventions_alts_new = list(filter(None, interventions_alts_new))\n",
    "        interventions_alts_new = [str(i) for i in interventions_alts_new]\n",
    "        \n",
    "    except:\n",
    "        print(\"No cache of terms found. Proceeding to map entire KG from scratch\")\n",
    "        conditions_new = conditions_list\n",
    "        interventions_new = interventions_list\n",
    "        interventions_alts_new = interventions_alts_list\n",
    "        \n",
    "    dict_new_terms = {\"conditions\": conditions_new, \"interventions\": interventions_new, \"interventions_alts\": interventions_alts_new}\n",
    "\n",
    "    return dict_new_terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a77e9-7ead-4ee6-a4df-d2aa636cc893",
   "metadata": {},
   "source": [
    "# Map new terms using MetaMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee1c310c-1087-4d72-bef2-53f535f92e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_nr_response(term_type, description, ct_intervention_type, chunk, csv_writer):\n",
    "# def run_metamap(term_pair, params, mm, term_type, csv_writer):\n",
    "\n",
    "def get_nr_response(orig_term):\n",
    "    print(\"TRYING NAME RESOLVER\")\n",
    "    def create_session():\n",
    "        s = requests.Session()\n",
    "        return s\n",
    "    \n",
    "    sess = create_session()\n",
    "    \n",
    "    \"\"\"   Runs Name Resolver   \"\"\"\n",
    "    nr_url = 'https://name-resolution-sri.renci.org/lookup'\n",
    "    max_retries = 3 \n",
    "    \n",
    "    input_term = orig_term # in MetaMap, we have to potentially deascii the term and lower case it...for Name Resolver, we don't need to do that. To keep columns consist with MetaMap output, we just keep it and say the original term and the input term are the same. For MetaMap, they might be different\n",
    "    retries = 0\n",
    "    params = {'string':orig_term, 'limit':1} # limit -1 makes this return all available equivalent CURIEs name resolver can give (deprecated)\n",
    "    while retries <= max_retries:\n",
    "        try:\n",
    "            r = sess.post(nr_url, params=params)\n",
    "            if r.status_code == 200:\n",
    "                mapping_tool_response = r.json()  # process Name Resolver response\n",
    "                return mapping_tool_response\n",
    "            else:\n",
    "                return None\n",
    "        except (requests.RequestException, ConnectionResetError, OSError) as ex:\n",
    "            print(f\"\\nName Resolver request failed for term: {term}. Error: {ex}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(f\"Retrying ({retries}/{max_retries}) after a delay.\")\n",
    "                time.sleep(2 ** retries)  # Increase the delay between retries exponentially\n",
    "            else:\n",
    "                print(f\"Max retries (Name Resolver) reached for term: {term}.\")\n",
    "                return None\n",
    "    \n",
    "    # request_count +=1\n",
    "    # if request_count % 50 == 0:  # if 50 requests to API have been made, sleep 10 secs\n",
    "    #     time.sleep(10)  \n",
    "    \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for ct_term in chunk:\n",
    "#         request_count +=1\n",
    "#         if request_count % 50 == 0:  # if 50 requests to API have been made, sleep 10 secs\n",
    "#             time.sleep(10)  \n",
    "\n",
    "#         input_term = ct_term # in MetaMap, we have to potentially deascii the term and lower case it...for Name Resolver, we don't need to do that. To keep columns consist with MetaMap output, we just keep it and say the original term and the input term are the same. For MetaMap, they might be different\n",
    "#         retries = 0\n",
    "#         params = {'string':ct_term, 'limit':1} # limit -1 makes this return all available equivalent CURIEs name resolver can give (deprecated)\n",
    "#         while retries <= max_retries:\n",
    "#             try:\n",
    "#                 r = sess.post(nr_url, params=params)\n",
    "#                 if r.status_code == 200:\n",
    "#                     mapping_tool_response = r.json()  # process Name Resolver response\n",
    "#                     row_to_write = [mapping_tool, term_type, ct_term, input_term,  mapping_tool_response]\n",
    "#                     csv_writer.writerow(row_to_write)\n",
    "#                     # print(row_to_write)\n",
    "#                     break\n",
    "#             except (requests.RequestException, ConnectionResetError, OSError) as ex:\n",
    "#                 print(f\"\\nName Resolver request failed for term: {term}. Error: {ex}\")\n",
    "#                 retries += 1\n",
    "#                 if retries < max_retries:\n",
    "#                     print(f\"Retrying ({retries}/{max_retries}) after a delay.\")\n",
    "#                     time.sleep(2 ** retries)  # Increase the delay between retries exponentially\n",
    "#                 else:\n",
    "#                     print(f\"Max retries (Name Resolver) reached for term: {term}. Moving to the next term.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c24efc4-8cab-4094-b2e4-bdb7c6fe5af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # nr_response = get_nr_response(orig_term)\n",
    "# # ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "# for i in [\"cordiceps\", \"chocolate\", \"diabetes mellitus\", \"blipadbloo\", \"catheter\", \"humira®\"]:\n",
    "#     nr_result = get_nr_response(i)\n",
    "#     if nr_result:\n",
    "#         nr_result\n",
    "#         nr_curie = nr_result[0][\"curie\"]\n",
    "#         nr_name = nr_result[0][\"label\"]\n",
    "#         nr_type = nr_result[0][\"types\"][0]\n",
    "#         nr_score = nr_result[0][\"score\"]\n",
    "#         new_concept_dict = {\"nameresolver_preferred_name\": nr_name,\n",
    "#                              \"nameresolver_cui\": nr_curie,\n",
    "#                              \"nameresolver_score\": nr_score,\n",
    "#                              \"nameresolver_semtypes\": nr_type}\n",
    "#     else:\n",
    "#         print(\"nothing returned from NR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18168da0-a8c3-481e-87cc-ae6fb4460739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_name = nr_result[0][\"label\"]\n",
    "nr_type = nr_result[0][\"types\"][0]\n",
    "nr_name\n",
    "nr_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8af1f-e785-494f-baca-a9f81604bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_nr_response(term_type, description, ct_intervention_type, chunk, csv_writer):\n",
    "#     # Format of cache output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response']\n",
    "\n",
    "#     def create_session():\n",
    "#         s = requests.Session()\n",
    "#         return s\n",
    "    \n",
    "#     sess = create_session()\n",
    "    \n",
    "#     \"\"\"   Runs Name Resolver   \"\"\"\n",
    "#     nr_url = 'https://name-resolution-sri.renci.org/lookup'\n",
    "#     max_retries = 3 \n",
    "    \n",
    "#     mapping_tool = \"name_resolver\"\n",
    "\n",
    "#     request_count = 0 # track how many times I'm making requests or hitting API\n",
    "#     for ct_term in chunk:\n",
    "#         request_count +=1\n",
    "#         if request_count % 50 == 0:  # if 50 requests to API have been made, sleep 10 secs\n",
    "#             time.sleep(10)  \n",
    "\n",
    "#         input_term = ct_term # in MetaMap, we have to potentially deascii the term and lower case it...for Name Resolver, we don't need to do that. To keep columns consist with MetaMap output, we just keep it and say the original term and the input term are the same. For MetaMap, they might be different\n",
    "#         retries = 0\n",
    "#         params = {'string':ct_term, 'limit':1} # limit -1 makes this return all available equivalent CURIEs name resolver can give (deprecated)\n",
    "#         while retries <= max_retries:\n",
    "#             try:\n",
    "#                 r = sess.post(nr_url, params=params)\n",
    "#                 if r.status_code == 200:\n",
    "#                     mapping_tool_response = r.json()  # process Name Resolver response\n",
    "#                     row_to_write = [mapping_tool, term_type, ct_term, input_term,  mapping_tool_response]\n",
    "#                     csv_writer.writerow(row_to_write)\n",
    "#                     # print(row_to_write)\n",
    "#                     break\n",
    "#             except (requests.RequestException, ConnectionResetError, OSError) as ex:\n",
    "#                 print(f\"\\nName Resolver request failed for term: {term}. Error: {ex}\")\n",
    "#                 retries += 1\n",
    "#                 if retries < max_retries:\n",
    "#                     print(f\"Retrying ({retries}/{max_retries}) after a delay.\")\n",
    "#                     time.sleep(2 ** retries)  # Increase the delay between retries exponentially\n",
    "#                 else:\n",
    "#                     print(f\"Max retries (Name Resolver) reached for term: {term}. Moving to the next term.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecc6d0-ba32-4456-ac99-28896d0d50e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def run_metamap(term_pair, params, mm, term_type, csv_writer):\n",
    "#     mapping_tool = \"metamap\"\n",
    "#     orig_term = term_pair[0]\n",
    "#     input_term = term_pair[1]\n",
    "#     from_metamap = []\n",
    "#     # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "\n",
    "#     if params.get(\"exclude_sts\") is None: # exclude_sts is used for Interventions. restrict_to_sts is used for Conditions. So, the logic is, if we're mapping Conditions, execute \"if\" part of code. If we're mapping Interventions, execute \"else\" part of code\n",
    "#         try:\n",
    "#             concepts,error = mm.extract_concepts([input_term],\n",
    "#                                                  restrict_to_sts = params[\"restrict_to_sts\"],\n",
    "#                                                  term_processing = params[\"term_processing\"],\n",
    "#                                                  ignore_word_order = params[\"ignore_word_order\"],\n",
    "#                                                  strict_model = params[\"strict_model\"],\n",
    "#                                                 )\n",
    "#             for concept in concepts:\n",
    "#                 concept_info = []\n",
    "#                 concept_info.extend([mapping_tool, term_type, orig_term, input_term]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "#                 concept = concept._asdict()\n",
    "#                 new_concept_dict  = {\"metamap_preferred_name\": concept.get(\"preferred_name\"),\n",
    "#                                      \"metamap_cui\": concept.get(\"cui\"),\n",
    "#                                      \"metamap_score\": concept.get(\"score\"),\n",
    "#                                      \"metamap_semtypes\": concept.get(\"semtypes\")}\n",
    "#                 concept_info.append(new_concept_dict)\n",
    "#                 concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "#                 from_metamap.append(concept_info)\n",
    "                \n",
    "#         except: # if no mapping tool response, append None for both the response and the score\n",
    "#             from_metamap.extend([mapping_tool, term_type, orig_term, input_term, None, None])   # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "\n",
    "#     else:\n",
    "#         try:\n",
    "#             concepts,error = mm.extract_concepts([input_term],\n",
    "#                                                  exclude_sts = params[\"exclude_sts\"],\n",
    "#                                                  term_processing = params[\"term_processing\"],\n",
    "#                                                  ignore_word_order = params[\"ignore_word_order\"],\n",
    "#                                                  strict_model = params[\"strict_model\"],\n",
    "#                                                 )\n",
    "#             for concept in concepts:\n",
    "#                 concept_info = []\n",
    "#                 concept_info.extend([mapping_tool, term_type, orig_term, input_term]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "#                 concept = concept._asdict()\n",
    "#                 new_concept_dict  = {\"metamap_preferred_name\": concept.get(\"preferred_name\"),\n",
    "#                                      \"metamap_cui\": concept.get(\"cui\"),\n",
    "#                                      \"metamap_score\": concept.get(\"score\"),\n",
    "#                                      \"metamap_semtypes\": concept.get(\"semtypes\")}\n",
    "#                 concept_info.append(new_concept_dict)\n",
    "#                 concept_info.append(None) # for score column\n",
    "#                 from_metamap.append(concept_info)\n",
    "\n",
    "#         except: # if no mapping tool response, append None for both the response and the score\n",
    "#             from_metamap.extend([mapping_tool, term_type, orig_term, input_term, None])   # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "#     # print(from_metamap)\n",
    "\n",
    "#     for result in from_metamap:\n",
    "#         # print(result)\n",
    "#         csv_writer.writerow(result)\n",
    "#     # return from_metamap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c54f747-2f68-49f5-b020-06ca183ba75f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_mappers(term_pair, params, mm, term_type, csv_writer):\n",
    "    mapping_tool = \"metamap\"\n",
    "    orig_term = term_pair[0]\n",
    "    input_term = term_pair[1]\n",
    "    from_mapper = []\n",
    "    \n",
    "    # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "\n",
    "    if params.get(\"exclude_sts\") is None: # exclude_sts is used for Interventions. restrict_to_sts is used for Conditions. So, the logic is, if we're mapping Conditions, execute \"if\" part of code. If we're mapping Interventions, execute \"else\" part of code\n",
    "        try:\n",
    "            concepts,error = mm.extract_concepts([input_term],\n",
    "                                     restrict_to_sts = params[\"restrict_to_sts\"],\n",
    "                                     term_processing = params[\"term_processing\"],\n",
    "                                     ignore_word_order = params[\"ignore_word_order\"],\n",
    "                                     strict_model = params[\"strict_model\"],)\n",
    "                                                    \n",
    "            if concepts:   # if MetaMap gives response, process response\n",
    "                for concept in concepts:\n",
    "                    concept_info = []\n",
    "                    concept_info.extend([mapping_tool, term_type, orig_term, input_term]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "                    concept = concept._asdict()\n",
    "                    new_concept_dict  = {\"metamap_preferred_name\": concept.get(\"preferred_name\"),\n",
    "                                         \"metamap_cui\": concept.get(\"cui\"),\n",
    "                                         \"metamap_score\": concept.get(\"score\"),\n",
    "                                         \"metamap_semtypes\": concept.get(\"semtypes\")}\n",
    "                    concept_info.append(new_concept_dict)\n",
    "                    concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "                    from_mapper.append(concept_info)\n",
    "            else:   # if MetaMap fails, try using Name Resolver and process response\n",
    "                print(\"ATTEMPTING NAME RESOLVER HERE\")\n",
    "                nr_response = get_nr_response(orig_term)\n",
    "                # run_mappers.nrcalls += 1\n",
    "                if nr_response: # if Name Resolver gives response, process repsonse\n",
    "                    input_term = orig_term # no preprocessing (lowercasing or deascii-ing) necessary to submit terms to Name Resolver (unlike MetaMap)\n",
    "                    mapping_tool = \"nameresolver\"\n",
    "                    concept_info = []\n",
    "                    \n",
    "                    nr_curie = nr_response[0][\"curie\"]\n",
    "                    nr_name = nr_response[0][\"label\"]\n",
    "                    nr_type = nr_response[0][\"types\"][0]\n",
    "                    nr_score = nr_response[0][\"score\"]\n",
    "                    new_concept_dict = {\"nameresolver_preferred_name\": nr_name,\n",
    "                                         \"nameresolver_cui\": nr_curie,\n",
    "                                         \"nameresolver_score\": nr_score,\n",
    "                                         \"nameresolver_semtypes\": nr_type}\n",
    "                    concept_info.extend([mapping_tool, term_type, orig_term, input_term])\n",
    "                    concept_info.append(new_concept_dict)\n",
    "                    concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "                    from_mapper.append(concept_info)\n",
    "                else:\n",
    "                    print(\"Nothing returned from NR or Metamap\")\n",
    "                    concept_info.extend([mapping_tool, term_type, orig_term, input_term, None, None])\n",
    "                    from_mapper.append(concept_info)\n",
    "        except:\n",
    "            print(\"Nothing returned from NR or Metamap\")\n",
    "            concept_info.extend([mapping_tool, term_type, orig_term, input_term, None, None])\n",
    "            from_mapper.append(concept_info)\n",
    "            \n",
    "    else:\n",
    "        try:\n",
    "            concepts,error = mm.extract_concepts([input_term],\n",
    "                                                 exclude_sts = params[\"exclude_sts\"],\n",
    "                                                 term_processing = params[\"term_processing\"],\n",
    "                                                 ignore_word_order = params[\"ignore_word_order\"],\n",
    "                                                 strict_model = params[\"strict_model\"],) \n",
    "                                                   \n",
    "            if concepts:   # if MetaMap gives response, process response\n",
    "                for concept in concepts:\n",
    "                    concept_info = []\n",
    "                    concept_info.extend([mapping_tool, term_type, orig_term, input_term]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "                    concept = concept._asdict()\n",
    "                    new_concept_dict  = {\"metamap_preferred_name\": concept.get(\"preferred_name\"),\n",
    "                                         \"metamap_cui\": concept.get(\"cui\"),\n",
    "                                         \"metamap_score\": concept.get(\"score\"),\n",
    "                                         \"metamap_semtypes\": concept.get(\"semtypes\")}\n",
    "                    concept_info.append(new_concept_dict)\n",
    "                    concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "                    from_mapper.append(concept_info)\n",
    "            else:   # if MetaMap fails, try using Name Resolver and process response\n",
    "                print(\"ATTEMPTING NAME RESOLVER HERE\")\n",
    "                nr_response = get_nr_response(orig_term)\n",
    "                # run_mappers.nrcalls += 1\n",
    "                if nr_response: # if Name Resolver gives response, process repsonse\n",
    "                    input_term = orig_term # no preprocessing (lowercasing or deascii-ing) necessary to submit terms to Name Resolver (unlike MetaMap)\n",
    "                    mapping_tool = \"nameresolver\"\n",
    "                    concept_info = []\n",
    "                    \n",
    "                    nr_curie = nr_response[0][\"curie\"]\n",
    "                    nr_name = nr_response[0][\"label\"]\n",
    "                    nr_type = nr_response[0][\"types\"][0]\n",
    "                    nr_score = nr_response[0][\"score\"]\n",
    "                    new_concept_dict = {\"nameresolver_preferred_name\": nr_name,\n",
    "                                         \"nameresolver_cui\": nr_curie,\n",
    "                                         \"nameresolver_score\": nr_score,\n",
    "                                         \"nameresolver_semtypes\": nr_type}\n",
    "                    concept_info.extend([mapping_tool, term_type, orig_term, input_term])\n",
    "                    concept_info.append(new_concept_dict)\n",
    "                    concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "                    from_mapper.append(concept_info)\n",
    "                else:\n",
    "                    print(\"Nothing returned from NR or Metamap\")\n",
    "                    concept_info.extend([mapping_tool, term_type, orig_term, input_term, None, None])\n",
    "                    from_mapper.append(concept_info)\n",
    "        except:\n",
    "            print(\"Nothing returned from NR or Metamap\")\n",
    "            concept_info.extend([mapping_tool, term_type, orig_term, input_term, None, None])\n",
    "            from_mapper.append(concept_info)\n",
    "               \n",
    "    \n",
    "#         try:\n",
    "#             concepts,error = mm.extract_concepts([input_term],\n",
    "#                                                  restrict_to_sts = params[\"restrict_to_sts\"],\n",
    "#                                                  term_processing = params[\"term_processing\"],\n",
    "#                                                  ignore_word_order = params[\"ignore_word_order\"],\n",
    "#                                                  strict_model = params[\"strict_model\"],\n",
    "#                                                 )\n",
    "#             if concepts: # if MetaMap gives response, process response\n",
    "#                 for concept in concepts:\n",
    "#                     concept_info = []\n",
    "#                     concept_info.extend([mapping_tool, term_type, orig_term, input_term]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "#                     concept = concept._asdict()\n",
    "#                     new_concept_dict  = {\"metamap_preferred_name\": concept.get(\"preferred_name\"),\n",
    "#                                          \"metamap_cui\": concept.get(\"cui\"),\n",
    "#                                          \"metamap_score\": concept.get(\"score\"),\n",
    "#                                          \"metamap_semtypes\": concept.get(\"semtypes\")}\n",
    "#                     concept_info.append(new_concept_dict)\n",
    "#                     concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "#                     from_mapper.append(concept_info)\n",
    "#             except: # if MetaMap fails, try using Name Resolver and process response\n",
    "#                 nr_response = get_nr_response(orig_term)\n",
    "#                 run_mappers.nrcalls += 1\n",
    "#                 if nr_response: # if Name Resolver gives response, process repsonse\n",
    "#                     input_term = orig_term # no preprocessing (lowercasing or deascii-ing) necessary to submit terms to Name Resolver (unlike MetaMap)\n",
    "#                     mapping_tool = \"nameresolver\"\n",
    "#                     concept_info = []\n",
    "                    \n",
    "#                     nr_curie = nr_response[0][\"curie\"]\n",
    "#                     nr_name = nr_response[0][\"label\"]\n",
    "#                     nr_type = nr_response[0][\"types\"][0]\n",
    "#                     nr_score = nr_response[0][\"score\"]\n",
    "#                     new_concept_dict = {\"nameresolver_preferred_name\": nr_name,\n",
    "#                                          \"nameresolver_cui\": nr_curie,\n",
    "#                                          \"nameresolver_score\": nr_score,\n",
    "#                                          \"nameresolver_semtypes\": nr_type}\n",
    "#                     concept_info.extend([mapping_tool, term_type, orig_term, input_term])\n",
    "#                     concept_info.append(new_concept_dict)\n",
    "#                     concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "#                     from_mapper.append(concept_info)\n",
    "#                 else: # both MetaMap and Name Resolver failed to give response, so put None for the response, but show that the term was attempted to be mapped\n",
    "#                     print(\"nothing returned from NR or Metamap\")\n",
    "#                     concept_info.extend([mapping_tool, term_type, orig_term, input_term, None, None])\n",
    "#                     from_mapper.append(concept_info)\n",
    "#     else:\n",
    "#         try:\n",
    "#             concepts,error = mm.extract_concepts([input_term],\n",
    "#                                                  exclude_sts = params[\"exclude_sts\"],\n",
    "#                                                  term_processing = params[\"term_processing\"],\n",
    "#                                                  ignore_word_order = params[\"ignore_word_order\"],\n",
    "#                                                  strict_model = params[\"strict_model\"],\n",
    "#                                                 ) \n",
    "#             if concepts: # if MetaMap gives response, process response\n",
    "#                 for concept in concepts:\n",
    "#                     concept_info = []\n",
    "#                     concept_info.extend([mapping_tool, term_type, orig_term, input_term]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "#                     concept = concept._asdict()\n",
    "#                     new_concept_dict  = {\"metamap_preferred_name\": concept.get(\"preferred_name\"),\n",
    "#                                          \"metamap_cui\": concept.get(\"cui\"),\n",
    "#                                          \"metamap_score\": concept.get(\"score\"),\n",
    "#                                          \"metamap_semtypes\": concept.get(\"semtypes\")}\n",
    "#                     concept_info.append(new_concept_dict)\n",
    "#                     concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "#                     from_mapper.append(concept_info)\n",
    "#         except: # if MetaMap fails, try using Name Resolver and process response\n",
    "#                 nr_response = get_nr_response(orig_term)\n",
    "#                 run_mappers.nrcalls += 1\n",
    "#                 if nr_response: # if Name Resolver gives response, process repsonse\n",
    "#                     input_term = orig_term # no preprocessing (lowercasing or deascii-ing) necessary to submit terms to Name Resolver (unlike MetaMap)\n",
    "#                     mapping_tool = \"nameresolver\"\n",
    "#                     concept_info = []\n",
    "                    \n",
    "#                     nr_curie = nr_response[0][\"curie\"]\n",
    "#                     nr_name = nr_response[0][\"label\"]\n",
    "#                     nr_type = nr_response[0][\"types\"][0]\n",
    "#                     nr_score = nr_response[0][\"score\"]\n",
    "#                     new_concept_dict = {\"nameresolver_preferred_name\": nr_name,\n",
    "#                                          \"nameresolver_cui\": nr_curie,\n",
    "#                                          \"nameresolver_score\": nr_score,\n",
    "#                                          \"nameresolver_semtypes\": nr_type}\n",
    "#                     concept_info.extend([mapping_tool, term_type, orig_term, input_term])\n",
    "#                     concept_info.append(new_concept_dict)\n",
    "#                     concept_info.append(None) # this is for the score column, empty bc not scored yet\n",
    "#                     from_mapper.append(concept_info)\n",
    "#                 else: # both MetaMap and Name Resolver failed to give response, so put None for the response, but show that the term was attempted to be mapped\n",
    "#                     print(\"nothing returned from NR or Metamap\")\n",
    "#                     concept_info.extend([mapping_tool, term_type, orig_term, input_term, None, None]) # Format of output TSV: header = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "#                     from_mapper.append(concept_info)\n",
    "    # print(from_mapper)\n",
    "\n",
    "    for result in from_mapper:\n",
    "        print(result)\n",
    "        # csv_writer.writerow(result)\n",
    "    # return from_metamap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485fd6bb-2e4a-40f5-bbc9-e92af2c16a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parallelize_mappers(term_pair_list, params, term_type, csv_writer):\n",
    "\n",
    "    LENGTH = len(term_pair_list)  # Number of iterations required to fill progress bar (pbar)\n",
    "    pbar = tqdm(total=LENGTH, desc=\"% {}s mapped\".format(term_type), position=0, leave=True, mininterval = LENGTH/20, bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}')  # Init progress bar\n",
    "\n",
    "    start_metamap_servers(metamap_dirs) # start the MetaMap servers\n",
    "    mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "    with concurrent.futures.ThreadPoolExecutor((multiprocessing.cpu_count()*2) - 1) as executor:\n",
    "        futures = [executor.submit(run_mappers, term_pair, params, mm, term_type, csv_writer) for term_pair in term_pair_list]\n",
    "        for _ in concurrent.futures.as_completed(futures):\n",
    "            pbar.update(n=1)  # Increments counter\n",
    "    stop_metamap_servers(metamap_dirs) # stop the MetaMap servers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001b34e-6004-4b1a-9324-63f3ec71a990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def parallelize_metamap(term_pair_list, params, term_type, csv_writer):\n",
    "\n",
    "#     LENGTH = len(term_pair_list)  # Number of iterations required to fill progress bar (pbar)\n",
    "#     pbar = tqdm(total=LENGTH, desc=\"% {}s mapped\".format(term_type), position=0, leave=True, mininterval = LENGTH/20, bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}')  # Init progress bar\n",
    "\n",
    "#     start_metamap_servers(metamap_dirs) # start the MetaMap servers\n",
    "#     mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "#     with concurrent.futures.ThreadPoolExecutor((multiprocessing.cpu_count()*2) - 1) as executor:\n",
    "#         futures = [executor.submit(run_metamap, term_pair, params, mm, term_type, csv_writer) for term_pair in term_pair_list]\n",
    "#         for _ in concurrent.futures.as_completed(futures):\n",
    "#             pbar.update(n=1)  # Increments counter\n",
    "#     stop_metamap_servers(metamap_dirs) # stop the MetaMap servers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f79ca09-cac5-4f30-a262-ff86690265e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def term_list_to_mappers(dict_new_terms):   \n",
    "    metamap_version = [int(s) for s in re.findall(r'\\d+', metamap_dirs.get('metamap_bin_dir'))] # get MetaMap version being run \n",
    "    deasciier = np.vectorize(de_ascii_er) # vectorize function\n",
    "    \n",
    "    # open mapping cache to add MetaMap terms\n",
    "    mapping_filename = \"mapping_cache.tsv\"\n",
    "    if os.path.exists(mapping_filename):\n",
    "        output = open(mapping_filename, 'a', newline='') \n",
    "        csv_writer = csv.writer(output, delimiter='\\t')\n",
    "    else:\n",
    "        output = open(mapping_filename, 'w+', newline='')\n",
    "        col_names = ['mapping_tool', 'term_type', 'clintrial_term', 'input_term', 'mapping_tool_response', 'score']\n",
    "        csv_writer = csv.writer(output, delimiter='\\t')\n",
    "        csv_writer.writerow(col_names)\n",
    "\n",
    "    #  - Conditions\n",
    "    condition_semantic_type_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    conditions = dict_new_terms.get(\"conditions\")\n",
    "    condition_params = {\"restrict_to_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False} # strict_model and relaxed_model are presumably opposites? relaxed_model = True is what I want, but that option appears to be broken in Pymetamap (returns no results when used). Using strict_model = False instead...\n",
    "    # conditon_term_type = \"condition\"\n",
    "\n",
    "    #  - Interventions\n",
    "    condition_semantic_type_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    interventions = dict_new_terms.get(\"interventions\")\n",
    "    intervention_params = {\"exclude_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False} # strict_model and relaxed_model are presumably opposites? relaxed_model = True is what I want, but that option appears to be broken in Pymetamap (returns no results when used). Using strict_model = False instead...\n",
    "    # intervention_term_type = \"intervention\"\n",
    "\n",
    "    #  - Alternate Interventions\n",
    "    condition_semantic_type_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    interventions_alts = dict_new_terms.get(\"interventions_alts\")\n",
    "    intervention_params = {\"exclude_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False} # strict_model and relaxed_model are presumably opposites? relaxed_model = True is what I want, but that option appears to be broken in Pymetamap (returns no results when used). Using strict_model = False instead...\n",
    "    # intervention_alternate_term_type = \"intervention_alternate\"\n",
    "    \n",
    "    if metamap_version[0] >= 20:\n",
    "        print(\"MetaMap version >= 2020, conduct mapping on original terms\")\n",
    "        # parallelize_metamap(list(zip(conditions, conditions)), condition_params, \"condition\", csv_writer)\n",
    "        # parallelize_metamap(list(zip(interventions, interventions)), intervention_params, \"intervention\", csv_writer)\n",
    "        # parallelize_metamap(list(zip(interventions_alts, interventions_alts)), intervention_alts_params, \"alternate_intervention\", csv_writer)\n",
    "        parallelize_mappers(list(zip(conditions, conditions)), condition_params, \"condition\", csv_writer)\n",
    "        parallelize_mappers(list(zip(interventions, interventions)), intervention_params, \"intervention\", csv_writer)\n",
    "        parallelize_mappers(list(zip(interventions_alts, interventions_alts)), intervention_alts_params, \"alternate_intervention\", csv_writer)\n",
    "    else:\n",
    "        print(\"MetaMap version < 2020, conduct mapping on terms after removing ascii characters\")\n",
    "        deascii_cons = deasciier(conditions)\n",
    "        deascii_ints = deasciier(interventions)\n",
    "        deascii_int_alts = deasciier(interventions_alts)\n",
    "        # parallelize_metamap(list(zip(conditions, deascii_cons)), condition_params, \"condition\", csv_writer)\n",
    "        # parallelize_metamap(list(zip(interventions, deascii_ints)), intervention_params, \"intervention\", csv_writer)\n",
    "        # parallelize_metamap(list(zip(interventions_alts, deascii_int_alts)), intervention_params, \"intervention_alternate\", csv_writer)\n",
    "        parallelize_mappers(list(zip(conditions, deascii_cons)), condition_params, \"condition\", csv_writer)\n",
    "        parallelize_mappers(list(zip(interventions, deascii_ints)), intervention_params, \"intervention\", csv_writer)\n",
    "        parallelize_mappers(list(zip(interventions_alts, deascii_int_alts)), intervention_params, \"intervention_alternate\", csv_writer)\n",
    "\n",
    "    output.close()\n",
    "    \n",
    "    \"\"\" Remove duplicate rows from cache \"\"\"\n",
    "    cache = pd.read_csv(mapping_filename, sep='\\t', index_col=False, header=0, on_bad_lines = 'warn')\n",
    "    cache = cache.drop_duplicates()\n",
    "    cache.to_csv(mapping_filename, sep=\"\\t\", index=False, header=True) # output deduplicated cache terms to TSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b40eb7-50af-40e8-8fc8-8cc4e506285c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def score_metamap_mappings():\n",
    "\n",
    "\n",
    "header = True\n",
    "with pd.read_csv(\"mapping_cache.tsv\", sep='\\t', index_col=False, header=0, on_bad_lines = 'warn', chunksize=1000) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk[\"scored\"] = np.where(~chunk[\"score\"].isnull(), chunk[\"score\"],\n",
    "                                   np.where((chunk.score.isnull())&(chunk.mapping_tool == \"metamap\"),\n",
    "        df['d'] = np.where(df.a.isnull(),\n",
    "         np.nan,\n",
    "         np.where((df.b == \"N\")&(~df.c.isnull()),\n",
    "                  df.a*df.c,\n",
    "                  df.a))\n",
    "        \n",
    "        \n",
    "#         for i, row in chunk.iterrows():\n",
    "#             print(type(row[\"score\"]))\n",
    "#             if not row[\"score\"].isnull():\n",
    "#                 print(i)\n",
    "# #                 break\n",
    "#             elif pd.isnull(row[\"score\"]) and row[\"mapping_tool\"] == \"metamap\":\n",
    "#                 mm_dict = ast.literal_eval(row[\"mapping_tool_response\"])\n",
    "#                 mapped_term = mm_dict['metamap_preferred_name']\n",
    "#                 sort_ratio_score = get_token_sort_ratio(row[\"clintrial_term\"], mapped_term)\n",
    "#                 similarity_score = get_similarity_score(row[\"clintrial_term\"], mapped_term)\n",
    "#                 max_score = max(sort_ratio_score, similarity_score)\n",
    "#                 chunk.at[i, \"score\"] = max_score\n",
    "#             elif pd.isnull(row[\"score\"]) and row[\"mapping_tool\"] == \"nameresolver\":\n",
    "#                 break\n",
    "            \n",
    "#             chunk.to_csv(\"mapping_cache_scored.tsv\", header=header, sep=\"\\t\", index=False, mode='a+')\n",
    "#             header = False\n",
    "\n",
    "#       header = True\n",
    "# for chunk in chunks:\n",
    "\n",
    "#     chunk.to_csv(os.path.join(folder, new_folder, \"new_file_\" + filename),\n",
    "#         header=header, cols=[['TIME','STUFF']], mode='a')\n",
    "\n",
    "#     header = False          \n",
    "                \n",
    "            \n",
    "# original_clintrial_term = row[\"clintrial_term\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ceddf5-0ebe-41d9-9b89-85fc647f4136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting download of Clinical Trial data as of 02_21_2024\n",
      "\n",
      "\n",
      "Failed to scrape AACT for download. Please navigate to https://aact.ctti-clinicaltrials.org/download and manually download zip file.\n",
      "Please store the downloaded zip in the /data directory. This should be the only item besides the cache file, condition manual review file, and intervention manual review file, in the directory at this time.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type Done when done:  Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at: \n",
      "/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/8vstm2enpo0ocbo2z7oypqurhgmz.zip\n",
      "Please make sure this the correct zip file from AACT\n",
      "Unzipping data into\n",
      "/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/02_20_2024_extracted\n",
      "MetaMap version < 2020, conduct mapping on terms after removing ascii characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:   5%|█                   | 1/20 [00:11<03:35, 11."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTEMPTING NAME RESOLVER HERE\n",
      "TRYING NAME RESOLVER\n",
      "['metamap', 'condition', 'tetraplegia', 'tetraplegia', {'metamap_preferred_name': 'Quadriplegia', 'metamap_cui': 'C0034372', 'metamap_score': '16.26', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['nameresolver', 'condition', 'thermogenesis', 'thermogenesis', {'nameresolver_preferred_name': 'Thermogenesis', 'nameresolver_cui': 'UMLS:C0018841', 'nameresolver_score': 99.5397, 'nameresolver_semtypes': 'biolink:PhysiologicalProcess'}, None]\n",
      "['metamap', 'condition', 'cardiovascular risk factor', 'cardiovascular risk factor', {'metamap_preferred_name': 'cardiovascular risk factor', 'metamap_cui': 'C0850624', 'metamap_score': '3.77', 'metamap_semtypes': '[dsyn]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:  20%|████                | 4/20 [00:12<00:40,  2."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'condition', 'hepatocellular carcinoma', 'hepatocellular carcinoma', {'metamap_preferred_name': 'Liver carcinoma', 'metamap_cui': 'C2239176', 'metamap_score': '19.49', 'metamap_semtypes': '[neop]'}, None]\n",
      "['metamap', 'condition', 'maturity-onset diabetes in the young (mody)', 'maturity-onset diabetes in the young (mody)', {'metamap_preferred_name': None, 'metamap_cui': None, 'metamap_score': None, 'metamap_semtypes': None}, None]\n",
      "['metamap', 'condition', 'maturity-onset diabetes in the young (mody)', 'maturity-onset diabetes in the young (mody)', {'metamap_preferred_name': 'Diabetes Mellitus, Non-Insulin-Dependent', 'metamap_cui': 'C0011860', 'metamap_score': '16.23', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'maturity-onset diabetes in the young (mody)', 'maturity-onset diabetes in the young (mody)', {'metamap_preferred_name': 'Young-onset diabetes', 'metamap_cui': 'C4227728', 'metamap_score': '3.60', 'metamap_semtypes': '[fndg]'}, None]\n",
      "['metamap', 'condition', 'acute kidney injury', 'acute kidney injury', {'metamap_preferred_name': 'Acute kidney injury', 'metamap_cui': 'C2609414', 'metamap_score': '19.54', 'metamap_semtypes': '[inpo]'}, None]\n",
      "['metamap', 'condition', 'acute kidney injury', 'acute kidney injury', {'metamap_preferred_name': 'Kidney Failure, Acute', 'metamap_cui': 'C0022660', 'metamap_score': '19.54', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'acute kidney injury', 'acute kidney injury', {'metamap_preferred_name': 'Acute Kidney Injury, CTCAE', 'metamap_cui': 'C4552597', 'metamap_score': '3.77', 'metamap_semtypes': '[fndg]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:  35%|███████             | 7/20 [00:13<00:18,  1."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'condition', 'human papilloma virus infection', 'human papilloma virus infection', {'metamap_preferred_name': 'Human papilloma virus infection', 'metamap_cui': 'C0343641', 'metamap_score': '10.12', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'hypertrophic obstructive cardiomyopathy', 'hypertrophic obstructive cardiomyopathy', {'metamap_preferred_name': 'Hypertrophic obstructive cardiomyopathy', 'metamap_cui': 'C4551472', 'metamap_score': '3.77', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'prehypertension', 'prehypertension', {'metamap_preferred_name': 'Prehypertension', 'metamap_cui': 'C1696708', 'metamap_score': '9.95', 'metamap_semtypes': '[dsyn]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:  50%|██████████          | 10/20 [00:16<00:11,  1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'condition', 'squamous cell carcinoma of the head and neck', 'squamous cell carcinoma of the head and neck', {'metamap_preferred_name': 'Squamous cell carcinoma of the head and neck', 'metamap_cui': 'C1168401', 'metamap_score': '19.70', 'metamap_semtypes': '[neop]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:  60%|████████████        | 12/20 [00:18<00:09,  1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'condition', 'attention deficit hyperactivity disorder', 'attention deficit hyperactivity disorder', {'metamap_preferred_name': 'Attention deficit hyperactivity disorder', 'metamap_cui': 'C1263846', 'metamap_score': '13.28', 'metamap_semtypes': '[mobd]'}, None]\n",
      "['metamap', 'condition', 'liver metastases', 'liver metastases', {'metamap_preferred_name': 'Secondary malignant neoplasm of liver', 'metamap_cui': 'C0494165', 'metamap_score': '3.72', 'metamap_semtypes': '[neop]'}, None]\n",
      "ATTEMPTING NAME RESOLVER HERE\n",
      "TRYING NAME RESOLVER\n",
      "['nameresolver', 'condition', 'safer sex', 'safer sex', {'nameresolver_preferred_name': \"sexually active and practicing 'safer sex'\", 'nameresolver_cui': 'UMLS:C2229924', 'nameresolver_score': 36.026413, 'nameresolver_semtypes': 'biolink:PhenotypicFeature'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:  70%|██████████████      | 14/20 [00:20<00:06,  1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTEMPTING NAME RESOLVER HERE\n",
      "TRYING NAME RESOLVER\n",
      "['metamap', 'condition', 'metabolic associated-dysfunction steatotic liver disease (masld)', 'metabolic associated-dysfunction steatotic liver disease (masld)', {'metamap_preferred_name': None, 'metamap_cui': None, 'metamap_score': None, 'metamap_semtypes': None}, None]\n",
      "['metamap', 'condition', 'metabolic associated-dysfunction steatotic liver disease (masld)', 'metabolic associated-dysfunction steatotic liver disease (masld)', {'metamap_preferred_name': 'Steatohepatitis', 'metamap_cui': 'C2711227', 'metamap_score': '9.69', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'metabolic associated-dysfunction steatotic liver disease (masld)', 'metabolic associated-dysfunction steatotic liver disease (masld)', {'metamap_preferred_name': 'Hepatic Metabolic derangement', 'metamap_cui': 'C0851734', 'metamap_score': '3.58', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'metabolic associated-dysfunction steatotic liver disease (masld)', 'metabolic associated-dysfunction steatotic liver disease (masld)', {'metamap_preferred_name': 'DYSFUNCTION - SKIN DISORDERS', 'metamap_cui': 'C3887505', 'metamap_score': '3.42', 'metamap_semtypes': '[dsyn]'}, None]\n",
      "['metamap', 'condition', 'metabolic associated-dysfunction steatotic liver disease (masld)', 'metabolic associated-dysfunction steatotic liver disease (masld)', {'metamap_preferred_name': 'Functional disorder', 'metamap_cui': 'C0277785', 'metamap_score': '3.42', 'metamap_semtypes': '[patf]'}, None]\n",
      "['metamap', 'condition', 'metabolic associated-dysfunction steatotic liver disease (masld)', 'metabolic associated-dysfunction steatotic liver disease (masld)', {'metamap_preferred_name': 'Fatty degeneration', 'metamap_cui': 'C0152254', 'metamap_score': '3.38', 'metamap_semtypes': '[patf]'}, None]\n",
      "['nameresolver', 'condition', 'acetabular surgery', 'acetabular surgery', {'nameresolver_preferred_name': 'Acetabular surgery', 'nameresolver_cui': 'UMLS:C1096435', 'nameresolver_score': 100.064, 'nameresolver_semtypes': 'biolink:Procedure'}, None]\n",
      "['metamap', 'condition', 'musculoskeletal neck pain', 'musculoskeletal neck pain', {'metamap_preferred_name': 'Musculoskeletal Pain', 'metamap_cui': 'C0026858', 'metamap_score': '16.24', 'metamap_semtypes': '[fndg]'}, None]\n",
      "['metamap', 'condition', 'musculoskeletal neck pain', 'musculoskeletal neck pain', {'metamap_preferred_name': 'Neck Pain, CTCAE 3.0', 'metamap_cui': 'C1963180', 'metamap_score': '3.64', 'metamap_semtypes': '[fndg]'}, None]\n",
      "['metamap', 'condition', 'musculoskeletal neck pain', 'musculoskeletal neck pain', {'metamap_preferred_name': 'Neck Pain, CTCAE 5.0', 'metamap_cui': 'C4553909', 'metamap_score': '3.64', 'metamap_semtypes': '[fndg]'}, None]\n",
      "['metamap', 'condition', 'musculoskeletal neck pain', 'musculoskeletal neck pain', {'metamap_preferred_name': 'Musculoskeletal:-:Point in time:^Patient:-', 'metamap_cui': 'C2707260', 'metamap_score': '3.44', 'metamap_semtypes': '[clna]'}, None]\n",
      "ATTEMPTING NAME RESOLVER HERE\n",
      "TRYING NAME RESOLVER\n",
      "['nameresolver', 'condition', 'attitude', 'attitude', {'nameresolver_preferred_name': 'Attitude', 'nameresolver_cui': 'UMLS:C0004271', 'nameresolver_score': 99.5397, 'nameresolver_semtypes': 'biolink:Behavior'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped:  90%|██████████████████  | 18/20 [00:22<00:01,  1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'condition', 'carcinoma, non-small-cell lung', 'carcinoma, non-small-cell lung', {'metamap_preferred_name': 'Non-Small Cell Lung Carcinoma', 'metamap_cui': 'C0007131', 'metamap_score': '25.86', 'metamap_semtypes': '[neop]'}, None]\n",
      "['metamap', 'condition', 'idiopathic myelofibrosis', 'idiopathic myelofibrosis', {'metamap_preferred_name': 'Primary Myelofibrosis', 'metamap_cui': 'C0001815', 'metamap_score': '16.33', 'metamap_semtypes': '[neop]'}, None]\n",
      "['metamap', 'condition', 'acute patella tendon rupture', 'acute patella tendon rupture', {'metamap_preferred_name': 'Traumatic rupture of patellar tendon', 'metamap_cui': 'C0263969', 'metamap_score': '3.65', 'metamap_semtypes': '[inpo]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped: 100%|████████████████████| 20/20 [00:24<00:00,  1\n",
      "% interventions mapped:   0%|                    | 0/19 [00:00<?, ?it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTEMPTING NAME RESOLVER HERE\n",
      "TRYING NAME RESOLVER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped:   5%|█                   | 1/19 [00:08<02:40, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing returned from NR or Metamap\n",
      "Nothing returned from NR or Metamap\n",
      "['metamap', 'intervention', 'propolis extract', 'propolis extract', {'metamap_preferred_name': 'Propolis', 'metamap_cui': 'C0033488', 'metamap_score': '16.21', 'metamap_semtypes': '[bacs,phsu]'}, None]\n",
      "['metamap', 'intervention', 'propolis extract', 'propolis extract', {'metamap_preferred_name': 'Propolis (fungal genus)', 'metamap_cui': 'C3160730', 'metamap_score': '3.59', 'metamap_semtypes': '[fngs]'}, None]\n",
      "['metamap', 'intervention', 'propolis extract', 'propolis extract', {'metamap_preferred_name': 'Extract (substance)', 'metamap_cui': 'C2828366', 'metamap_score': '3.45', 'metamap_semtypes': '[sbst]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped:  16%|███▏                | 3/19 [00:10<00:48, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention', 'laboratory biomarker analysis', 'laboratory biomarker analysis', {'metamap_preferred_name': 'Laboratory Biomarker Analysis', 'metamap_cui': 'C1881352', 'metamap_score': '3.77', 'metamap_semtypes': '[lbpr]'}, None]\n",
      "['metamap', 'intervention', 'mindfulness meditation', 'mindfulness meditation', {'metamap_preferred_name': 'Mindfulness', 'metamap_cui': 'C3542996', 'metamap_score': '16.21', 'metamap_semtypes': '[menp]'}, None]\n",
      "['metamap', 'intervention', 'mindfulness meditation', 'mindfulness meditation', {'metamap_preferred_name': 'meditation', 'metamap_cui': 'C0150277', 'metamap_score': '16.21', 'metamap_semtypes': '[menp]'}, None]\n",
      "['metamap', 'intervention', 'mindfulness meditation', 'mindfulness meditation', {'metamap_preferred_name': 'Meditation Therapy', 'metamap_cui': 'C0814263', 'metamap_score': '3.59', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention', 'mindfulness meditation', 'mindfulness meditation', {'metamap_preferred_name': 'Mental concentration', 'metamap_cui': 'C0086045', 'metamap_score': '3.59', 'metamap_semtypes': '[menp]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped:  26%|█████▎              | 5/19 [00:12<00:25, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention', 'part 2 focus group', 'part 2 focus group', {'metamap_preferred_name': 'Focus Groups', 'metamap_cui': 'C0016400', 'metamap_score': '16.22', 'metamap_semtypes': '[grup]'}, None]\n",
      "['metamap', 'intervention', 'part 2 focus group', 'part 2 focus group', {'metamap_preferred_name': 'acireductone dioxygenase [iron(II)-requiring] activity', 'metamap_cui': 'C1817569', 'metamap_score': '3.46', 'metamap_semtypes': '[moft]'}, None]\n",
      "['metamap', 'intervention', 'part 2 focus group', 'part 2 focus group', {'metamap_preferred_name': 'Part', 'metamap_cui': 'C0449719', 'metamap_score': '3.43', 'metamap_semtypes': '[spco]'}, None]\n",
      "['metamap', 'intervention', 'part 2 focus group', 'part 2 focus group', {'metamap_preferred_name': 'Part Dosing Unit', 'metamap_cui': 'C1709471', 'metamap_score': '3.43', 'metamap_semtypes': '[qnco]'}, None]\n",
      "['metamap', 'intervention', 'skin prick test', 'skin prick test', {'metamap_preferred_name': 'Skin prick test', 'metamap_cui': 'C0430561', 'metamap_score': '3.77', 'metamap_semtypes': '[diap]'}, None]\n",
      "['metamap', 'intervention', 'q.static (q. mrac) for respiratory motion correction', 'q.static (q. mrac) for respiratory motion correction', {'metamap_preferred_name': 'Motion', 'metamap_cui': 'C0026597', 'metamap_score': '6.57', 'metamap_semtypes': '[npop]'}, None]\n",
      "['metamap', 'intervention', 'q.static (q. mrac) for respiratory motion correction', 'q.static (q. mrac) for respiratory motion correction', {'metamap_preferred_name': 'Static', 'metamap_cui': 'C0441463', 'metamap_score': '3.54', 'metamap_semtypes': '[qlco]'}, None]\n",
      "['metamap', 'intervention', 'q.static (q. mrac) for respiratory motion correction', 'q.static (q. mrac) for respiratory motion correction', {'metamap_preferred_name': 'Correction (change)', 'metamap_cui': 'C1947976', 'metamap_score': '3.42', 'metamap_semtypes': '[ftcn]'}, None]\n",
      "['metamap', 'intervention', 'q.static (q. mrac) for respiratory motion correction', 'q.static (q. mrac) for respiratory motion correction', {'metamap_preferred_name': 'Correction Report', 'metamap_cui': 'C1705565', 'metamap_score': '3.42', 'metamap_semtypes': '[inpr]'}, None]\n",
      "['metamap', 'intervention', 'q.static (q. mrac) for respiratory motion correction', 'q.static (q. mrac) for respiratory motion correction', {'metamap_preferred_name': 'Specimen Source Codes - Respiratory', 'metamap_cui': 'C1546767', 'metamap_score': '3.42', 'metamap_semtypes': '[inpr]'}, None]\n",
      "['metamap', 'intervention', 'q.static (q. mrac) for respiratory motion correction', 'q.static (q. mrac) for respiratory motion correction', {'metamap_preferred_name': 'respiratory', 'metamap_cui': 'C0521346', 'metamap_score': '3.42', 'metamap_semtypes': '[ftcn]'}, None]\n",
      "['metamap', 'intervention', 'asoprisnil', 'asoprisnil', {'metamap_preferred_name': 'asoprisnil', 'metamap_cui': 'C1455381', 'metamap_score': '13.10', 'metamap_semtypes': '[orch,phsu]'}, None]\n",
      "ATTEMPTING NAME RESOLVER HERE\n",
      "TRYING NAME RESOLVER\n",
      "['metamap', 'intervention', 'augmented exposure therapy', 'augmented exposure therapy', {'metamap_preferred_name': 'Distance Counseling', 'metamap_cui': 'C1510538', 'metamap_score': '19.39', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention', 'augmented exposure therapy', 'augmented exposure therapy', {'metamap_preferred_name': 'Exposure to', 'metamap_cui': 'C0332157', 'metamap_score': '3.44', 'metamap_semtypes': '[qlco]'}, None]\n",
      "['metamap', 'intervention', 'augmented exposure therapy', 'augmented exposure therapy', {'metamap_preferred_name': 'Increased', 'metamap_cui': 'C0205217', 'metamap_score': '3.44', 'metamap_semtypes': '[qnco]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped:  53%|██████████▌         | 10/19 [00:13<00:07,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nameresolver', 'intervention', 'pnf', 'pnf', {'nameresolver_preferred_name': 'PNF protein, Arabidopsis', 'nameresolver_cui': 'MESH:C561284', 'nameresolver_score': 21.310198, 'nameresolver_semtypes': 'biolink:ChemicalEntity'}, None]\n",
      "['metamap', 'intervention', 'keeping adults physically active (kapa) intervention', 'keeping adults physically active (kapa) intervention', {'metamap_preferred_name': None, 'metamap_cui': None, 'metamap_score': None, 'metamap_semtypes': None}, None]\n",
      "['metamap', 'intervention', 'keeping adults physically active (kapa) intervention', 'keeping adults physically active (kapa) intervention', {'metamap_preferred_name': 'Adult', 'metamap_cui': 'C0001675', 'metamap_score': '9.74', 'metamap_semtypes': '[aggp]'}, None]\n",
      "['metamap', 'intervention', 'keeping adults physically active (kapa) intervention', 'keeping adults physically active (kapa) intervention', {'metamap_preferred_name': 'Intervention regimes', 'metamap_cui': 'C1273869', 'metamap_score': '3.55', 'metamap_semtypes': '[hlca]'}, None]\n",
      "['metamap', 'intervention', 'keeping adults physically active (kapa) intervention', 'keeping adults physically active (kapa) intervention', {'metamap_preferred_name': 'Interventional procedure', 'metamap_cui': 'C0184661', 'metamap_score': '3.55', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention', 'keeping adults physically active (kapa) intervention', 'keeping adults physically active (kapa) intervention', {'metamap_preferred_name': 'Nursing interventions', 'metamap_cui': 'C0886296', 'metamap_score': '3.55', 'metamap_semtypes': '[hlca]'}, None]\n",
      "['metamap', 'intervention', 'keeping adults physically active (kapa) intervention', 'keeping adults physically active (kapa) intervention', {'metamap_preferred_name': 'Retained', 'metamap_cui': 'C0333118', 'metamap_score': '3.41', 'metamap_semtypes': '[ftcn]'}, None]\n",
      "['metamap', 'intervention', 'healon5', 'healon5', {'metamap_preferred_name': 'Healon5', 'metamap_cui': 'C1170312', 'metamap_score': '3.64', 'metamap_semtypes': '[orch,phsu]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped:  68%|█████████████▋      | 13/19 [00:16<00:05,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention', 'project x 5.1ml', 'project x 5.1ml', {'metamap_preferred_name': 'Project', 'metamap_cui': 'C1709701', 'metamap_score': '3.43', 'metamap_semtypes': '[cnce]'}, None]\n",
      "['metamap', 'intervention', 'messaging', 'messaging', {'metamap_preferred_name': 'message', 'metamap_cui': 'C0470166', 'metamap_score': '3.60', 'metamap_semtypes': '[inpr]'}, None]\n",
      "['metamap', 'intervention', 'tumor biopsy', 'tumor biopsy', {'metamap_preferred_name': 'Biopsy', 'metamap_cui': 'C0005558', 'metamap_score': '19.36', 'metamap_semtypes': '[diap]'}, None]\n",
      "['metamap', 'intervention', 'tumor biopsy', 'tumor biopsy', {'metamap_preferred_name': 'biopsy characteristics', 'metamap_cui': 'C0220797', 'metamap_score': '3.59', 'metamap_semtypes': '[ftcn]'}, None]\n",
      "['metamap', 'intervention', 'tumor biopsy', 'tumor biopsy', {'metamap_preferred_name': 'Specimen Source Codes - tumor', 'metamap_cui': 'C1578706', 'metamap_score': '3.45', 'metamap_semtypes': '[inpr]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped:  84%|████████████████▊   | 16/19 [00:19<00:02,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention', 'autologous hematopoietic stem cell transplantation', 'autologous hematopoietic stem cell transplantation', {'metamap_preferred_name': 'Transplantation of autologous hematopoietic stem cell', 'metamap_cui': 'C1831743', 'metamap_score': '3.85', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention', 'dog training education', 'dog training education', {'metamap_preferred_name': 'Canis familiaris', 'metamap_cui': 'C0012984', 'metamap_score': '28.67', 'metamap_semtypes': '[mamm]'}, None]\n",
      "['metamap', 'intervention', 'dog training education', 'dog training education', {'metamap_preferred_name': 'education and training', 'metamap_cui': 'C0582584', 'metamap_score': '3.64', 'metamap_semtypes': '[edac]'}, None]\n",
      "['metamap', 'intervention', 'dog training education', 'dog training education', {'metamap_preferred_name': 'Dog family', 'metamap_cui': 'C1280551', 'metamap_score': '3.44', 'metamap_semtypes': '[mamm]'}, None]\n",
      "['metamap', 'intervention', 'intravenous injection of labeled crbc', 'intravenous injection of labeled crbc', {'metamap_preferred_name': 'Intravenous Injections', 'metamap_cui': 'C0021494', 'metamap_score': '16.21', 'metamap_semtypes': '[ftcn]'}, None]\n",
      "['metamap', 'intervention', 'intravenous injection of labeled crbc', 'intravenous injection of labeled crbc', {'metamap_preferred_name': 'Labeled (qualifier)', 'metamap_cui': 'C1708632', 'metamap_score': '3.43', 'metamap_semtypes': '[qlco]'}, None]\n",
      "['metamap', 'intervention', 'the babel approach to advance care planning in nursing homes', 'the babel approach to advance care planning in nursing homes', {'metamap_preferred_name': 'Advance Care Planning', 'metamap_cui': 'C0600371', 'metamap_score': '16.06', 'metamap_semtypes': '[hlca]'}, None]\n",
      "['metamap', 'intervention', 'the babel approach to advance care planning in nursing homes', 'the babel approach to advance care planning in nursing homes', {'metamap_preferred_name': 'Nursing Homes', 'metamap_cui': 'C0028688', 'metamap_score': '12.89', 'metamap_semtypes': '[hcro,mnob]'}, None]\n",
      "['metamap', 'intervention', 'the babel approach to advance care planning in nursing homes', 'the babel approach to advance care planning in nursing homes', {'metamap_preferred_name': 'Approach', 'metamap_cui': 'C0449445', 'metamap_score': '3.42', 'metamap_semtypes': '[spco]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped: 100%|████████████████████| 19/19 [00:22<00:00,\n",
      "% intervention_alternates mapped:   5%|█                   | 1/20 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention_alternate', 'dexinoral', 'dexinoral', {'metamap_preferred_name': 'Dexinoral', 'metamap_cui': 'C1511856', 'metamap_score': '3.64', 'metamap_semtypes': '[orch,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rt', 'rt', {'metamap_preferred_name': 'Structure of right thigh', 'metamap_cui': 'C0230425', 'metamap_score': '3.64', 'metamap_semtypes': '[bpoc]'}, None]\n",
      "['metamap', 'intervention_alternate', 'mk-3475', 'mk-3475', {'metamap_preferred_name': 'MK-3475', 'metamap_cui': 'C3660977', 'metamap_score': '3.72', 'metamap_semtypes': '[aapp,imft,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'meticorten', 'meticorten', {'metamap_preferred_name': 'Meticorten', 'metamap_cui': 'C0728770', 'metamap_score': '22.57', 'metamap_semtypes': '[orch,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', '1-ohp', '1-ohp', {'metamap_preferred_name': '2,3-diketo-5-methylthiopentyl-1-phosphate enolase activity', 'metamap_cui': 'C2248614', 'metamap_score': '3.52', 'metamap_semtypes': '[moft]'}, None]\n",
      "['metamap', 'intervention_alternate', '1-ohp', '1-ohp', {'metamap_preferred_name': 'acireductone synthase activity', 'metamap_cui': 'C2266809', 'metamap_score': '3.52', 'metamap_semtypes': '[moft]'}, None]\n",
      "['metamap', 'intervention_alternate', 'nmr imaging', 'nmr imaging', {'metamap_preferred_name': 'Magnetic Resonance Imaging', 'metamap_cui': 'C0024485', 'metamap_score': '16.33', 'metamap_semtypes': '[diap]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% intervention_alternates mapped:  35%|███████             | 7/20 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention_alternate', 'in vivo exposure', 'in vivo exposure', {'metamap_preferred_name': 'Exposure to', 'metamap_cui': 'C0332157', 'metamap_score': '3.57', 'metamap_semtypes': '[qlco]'}, None]\n",
      "['metamap', 'intervention_alternate', 'in vivo exposure', 'in vivo exposure', {'metamap_preferred_name': 'in vivo', 'metamap_cui': 'C1515655', 'metamap_score': '3.48', 'metamap_semtypes': '[spco]'}, None]\n",
      "['metamap', 'intervention_alternate', 'azacytidine', 'azacytidine', {'metamap_preferred_name': 'Azacitidine', 'metamap_cui': 'C0004475', 'metamap_score': '19.41', 'metamap_semtypes': '[nnon,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'hsct', 'hsct', {'metamap_preferred_name': 'Hemopoietic stem cell transplant', 'metamap_cui': 'C0472699', 'metamap_score': '19.41', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention_alternate', 'hsct', 'hsct', {'metamap_preferred_name': 'Allogeneic Hematopoietic Stem Cell Transplantation', 'metamap_cui': 'C1705576', 'metamap_score': '3.64', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention_alternate', 'midamor', 'midamor', {'metamap_preferred_name': 'Midamor', 'metamap_cui': 'C0026054', 'metamap_score': '13.10', 'metamap_semtypes': '[orch,phsu]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% intervention_alternates mapped:  55%|███████████         | 11/20 [00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention_alternate', 'audiological assessment', 'audiological assessment', {'metamap_preferred_name': 'Audiological evaluation', 'metamap_cui': 'C0200297', 'metamap_score': '3.72', 'metamap_semtypes': '[diap]'}, None]\n",
      "['metamap', 'intervention_alternate', 'hy209 gel', 'hy209 gel', {'metamap_preferred_name': 'Gel', 'metamap_cui': 'C0017243', 'metamap_score': '13.05', 'metamap_semtypes': '[bodm]'}, None]\n",
      "['metamap', 'intervention_alternate', 'hy209 gel', 'hy209 gel', {'metamap_preferred_name': 'Gel physical state', 'metamap_cui': 'C1382104', 'metamap_score': '3.59', 'metamap_semtypes': '[sbst]'}, None]\n",
      "['metamap', 'intervention_alternate', 'chondroitin', 'chondroitin', {'metamap_preferred_name': 'Chondroitin', 'metamap_cui': 'C0008454', 'metamap_score': '13.10', 'metamap_semtypes': '[bacs,orch,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'leucovorin', 'leucovorin', {'metamap_preferred_name': 'Leucovorin', 'metamap_cui': 'C0023413', 'metamap_score': '28.87', 'metamap_semtypes': '[orch,phsu,vita]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rhizoma coptidis and shen-ling-bai-zhu-san', 'rhizoma coptidis and shen-ling-bai-zhu-san', {'metamap_preferred_name': 'shen ling bai zhu', 'metamap_cui': 'C2605723', 'metamap_score': '12.93', 'metamap_semtypes': '[bacs]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rhizoma coptidis and shen-ling-bai-zhu-san', 'rhizoma coptidis and shen-ling-bai-zhu-san', {'metamap_preferred_name': 'Huang Lian preparation', 'metamap_cui': 'C0696725', 'metamap_score': '3.56', 'metamap_semtypes': '[phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rhizoma coptidis and shen-ling-bai-zhu-san', 'rhizoma coptidis and shen-ling-bai-zhu-san', {'metamap_preferred_name': 'NAA50 gene', 'metamap_cui': 'C1826357', 'metamap_score': '3.42', 'metamap_semtypes': '[gngm]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% intervention_alternates mapped:  80%|████████████████    | 16/20 [00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'Oxides', 'metamap_cui': 'C0030015', 'metamap_score': '16.15', 'metamap_semtypes': '[inch]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': '2 Hours', 'metamap_cui': 'C1292425', 'metamap_score': '3.53', 'metamap_semtypes': '[tmco]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'BAG3 wt Allele', 'metamap_cui': 'C3811385', 'metamap_score': '3.53', 'metamap_semtypes': '[gngm]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'Body Image Scale', 'metamap_cui': 'C3540495', 'metamap_score': '3.53', 'metamap_semtypes': '[inpr]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'MONOHYDRATE', 'metamap_cui': 'C1572759', 'metamap_score': '3.53', 'metamap_semtypes': '[orch]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'Organic Oxide', 'metamap_cui': 'C2986642', 'metamap_score': '3.53', 'metamap_semtypes': '[chvf]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'Twice weekly', 'metamap_cui': 'C0556985', 'metamap_score': '3.53', 'metamap_semtypes': '[tmco]'}, None]\n",
      "['metamap', 'intervention_alternate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', '2h-1,3,2-oxazaphosphorine, 2-[bis(2-chloroethyl)amino]tetrahydro-, 2-oxide, monohydrate', {'metamap_preferred_name': 'biphenyl synthase activity', 'metamap_cui': 'C2247301', 'metamap_score': '3.53', 'metamap_semtypes': '[moft]'}, None]\n",
      "['metamap', 'intervention_alternate', 'fluorouracil', 'fluorouracil', {'metamap_preferred_name': 'Fluorouracil', 'metamap_cui': 'C0016360', 'metamap_score': '19.41', 'metamap_semtypes': '[nnon,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'ticagrelor', 'ticagrelor', {'metamap_preferred_name': 'Ticagrelor', 'metamap_cui': 'C1999375', 'metamap_score': '22.57', 'metamap_semtypes': '[nnon,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'loxo 101', 'loxo 101', {'metamap_preferred_name': 'LOXO-101', 'metamap_cui': 'C3896823', 'metamap_score': '3.72', 'metamap_semtypes': '[aapp,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'Adoptive Immunotherapy', 'metamap_cui': 'C0079613', 'metamap_score': '25.50', 'metamap_semtypes': '[topp]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'Rilpivirine', 'metamap_cui': 'C1566826', 'metamap_score': '13.03', 'metamap_semtypes': '[nnon,phsu]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'SERPINA3 protein, human', 'metamap_cui': 'C1869853', 'metamap_score': '12.88', 'metamap_semtypes': '[aapp,bacs]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'Long', 'metamap_cui': 'C0205166', 'metamap_score': '3.44', 'metamap_semtypes': '[qlco]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'Long Variable', 'metamap_cui': 'C1706317', 'metamap_score': '3.44', 'metamap_semtypes': '[qlco]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'ACTG2 wt Allele', 'metamap_cui': 'C1704930', 'metamap_score': '3.42', 'metamap_semtypes': '[gngm]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'Asthma Control Test Questionnaire', 'metamap_cui': 'C4048375', 'metamap_score': '3.42', 'metamap_semtypes': '[inpr]'}, None]\n",
      "['metamap', 'intervention_alternate', 'rilpivirine long-acting', 'rilpivirine long-acting', {'metamap_preferred_name': 'SERPINA3 wt Allele', 'metamap_cui': 'C3890007', 'metamap_score': '3.42', 'metamap_semtypes': '[gngm]'}, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% intervention_alternates mapped: 100%|████████████████████| 20/20 [00\n"
     ]
    }
   ],
   "source": [
    "flag_and_path = get_raw_ct_data() # download raw data\n",
    "global metamap_dirs\n",
    "metamap_dirs = check_os()\n",
    "subset_size = 20\n",
    "df_dict = read_raw_ct_data(flag_and_path, subset_size) # read the clinical trial data\n",
    "dict_new_terms = check_against_cache(df_dict) # use the existing cache of MetaMapped terms so that only new terms are mapped\n",
    "term_list_to_mappers(dict_new_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588dde2b-142d-4d88-9b6b-eb49c6fb5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flag_and_path = get_raw_ct_data() # download raw data\n",
    "\n",
    "global metamap_dirs\n",
    "metamap_dirs = check_os()\n",
    "df_dict = read_raw_ct_data(flag_and_path, subset_size) # read the clinical trial data\n",
    "dict_new_terms = check_against_cache(df_dict, flag_and_path) # use the existing cache of MetaMapped terms so that only new terms are mapped\n",
    "\n",
    "term_list_to_mm(dict_new_terms, flag_and_path) # map new terms using MetaMap\n",
    "\n",
    "map_to_trial(flag_and_path) # map MetaMap terms back to trial \n",
    "score_mappings(flag_and_path) # score the mappings\n",
    "auto_select_curies(flag_and_path) # select CURIEs automatically that pass score threshold\n",
    "\n",
    "# compile_curies_for_trials(flag_and_path) # select CURIEs automatically that pass score threshold\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
